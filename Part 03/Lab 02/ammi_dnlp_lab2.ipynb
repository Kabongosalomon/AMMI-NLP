{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ammi_dnlp_lab2.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/louismartin/ammi-2019-bordes-DeepNLP/blob/master/lab2/ammi_dnlp_lab2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "rzBHf68UXD2k",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Chit Chat Chatbots"
      ]
    },
    {
      "metadata": {
        "id": "Jm6rTDCrXJ4V",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "In the previous lab, we explored models that try to answer questions by reasoning over free-text input. In this lab, we will explore two types of models to create chatbots.\n",
        "\n",
        "First, let's consider important qualities for a chit-chat chatbot system\n",
        "\n",
        "\n",
        "1.   **Readability** - whatever model we use, the chats it creates should be easily understood by humans\n",
        "2.   **Consistency** - when chatting with a chatbot, the bot should maintain consistent information. Imagine a bot that says \"Hi I'm Jack'' and then \"Hello, my name is Jane\" - quite confusing\n",
        "3.    **Engaging** - To encourage users to talk to the bot, the bot should be able to generate interesting, engaging responses. If the only response was \"wow, that's cool,\" users are quite unlikely to want to talk very much to the chat bot\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "LrYcmfoI5PWO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 171
        },
        "outputId": "f40c83fb-a481-4436-cb76-07121c508e48"
      },
      "cell_type": "code",
      "source": [
        "%%html\n",
        "<p style='color: blue;'>\n",
        "  Throughout the lab, there will be <b>questions</b> you should answer. <b>All questions you need to write an answer to will be in this blue color.</b>\n",
        "  \n",
        "  <br>Please write brief answers- no need for long explanations. \n",
        "  <br>There can be multiple correct answers to the questions.\n",
        "  \n",
        "  <br><br>The goal of these questions is to:\n",
        "  <ul style='color: blue;'>\n",
        "    <li> Review the lecture material in the context of practical models\n",
        "    <li> Develop a sense of experimentation\n",
        "  </ul>\n",
        "\n",
        "  \n",
        "</p>"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style='color: blue;'>\n",
              "  Throughout the lab, there will be <b>questions</b> you should answer. <b>All questions you need to write an answer to will be in this blue color.</b>\n",
              "  \n",
              "  <br>Please write brief answers- no need for long explanations. \n",
              "  <br>There can be multiple correct answers to the questions.\n",
              "  \n",
              "  <br><br>The goal of these questions is to:\n",
              "  <ul style='color: blue;'>\n",
              "    <li> Review the lecture material in the context of practical models\n",
              "    <li> Develop a sense of experimentation\n",
              "  </ul>\n",
              "\n",
              "  \n",
              "</p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "C3zg0WczXjDs",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Data"
      ]
    },
    {
      "metadata": {
        "id": "kguDIJbLXmZU",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "The dataset we will use for this lab is called `PersonaChat` - it was created to directly address problem 2. Each person talking in the dataset has a personality, which helps maintain consistency in the dialogue. We saw it last week in the tutorials as well (when you worked through beam search)"
      ]
    },
    {
      "metadata": {
        "id": "RpvTb8bBX40A",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/facebookresearch/ParlAI.git ~/ParlAI  > /dev/null\n",
        "!cd ~/ParlAI; python setup.py develop > /dev/null"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "3OJJ-L5RCyYT",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Example: **\n",
        "\n",
        "your persona: i just started college.\n",
        "\n",
        "your persona: i have 3 science classes.\n",
        "\n",
        "your persona: i work part time in the campus library.\n",
        "\n",
        "your persona: i am living at home but hope to live in the dorms next year.\n",
        "\n",
        "**Partner Dialogue**: hi how are you doing\n",
        "\n",
        "**Your Response**: great ! just got off work and relaxing before i study"
      ]
    },
    {
      "metadata": {
        "id": "Oe72XiqFXCS0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1601
        },
        "outputId": "1f33cfee-169b-402a-8e8b-73077ba724c2"
      },
      "cell_type": "code",
      "source": [
        "# let's download and take a look at some examples of data in PersonaChat\n",
        "!python ~/ParlAI/examples/display_data.py --task personachat --datatype train"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[ optional arguments: ] \n",
            "[  display_ignore_fields: agent_reply ]\n",
            "[  max_display_len: 1000 ]\n",
            "[  num_examples: 10 ]\n",
            "[ Main ParlAI Arguments: ] \n",
            "[  batchsize: 1 ]\n",
            "[  datapath: /root/ParlAI/data ]\n",
            "[  datatype: train ]\n",
            "[  download_path: /root/ParlAI/downloads ]\n",
            "[  hide_labels: False ]\n",
            "[  image_mode: raw ]\n",
            "[  multitask_weights: [1] ]\n",
            "[  numthreads: 1 ]\n",
            "[  show_advanced_args: False ]\n",
            "[  task: personachat ]\n",
            "[ ParlAI Model Arguments: ] \n",
            "[  dict_class: None ]\n",
            "[  init_model: None ]\n",
            "[  model: None ]\n",
            "[  model_file: None ]\n",
            "[ PytorchData Arguments: ] \n",
            "[  batch_length_range: 5 ]\n",
            "[  batch_sort_cache_type: pop ]\n",
            "[  batch_sort_field: text ]\n",
            "[  numworkers: 4 ]\n",
            "[  pytorch_context_length: -1 ]\n",
            "[  pytorch_datapath: None ]\n",
            "[  pytorch_include_labels: True ]\n",
            "[  pytorch_preprocess: False ]\n",
            "[  pytorch_teacher_batch_sort: False ]\n",
            "[  pytorch_teacher_dataset: None ]\n",
            "[  pytorch_teacher_task: None ]\n",
            "[  shuffle: False ]\n",
            "[ ParlAI Image Preprocessing Arguments: ] \n",
            "[  image_cropsize: 224 ]\n",
            "[  image_size: 256 ]\n",
            "[creating task(s): personachat]\n",
            "[building data: /root/ParlAI/data/Persona-Chat]\n",
            "[ downloading: http://parl.ai/downloads/personachat/personachat.tgz to /root/ParlAI/data/Persona-Chat/personachat.tgz ]\n",
            "Downloading personachat.tgz: 100% 223M/223M [00:20<00:00, 11.0MB/s]\n",
            "unpacking personachat.tgz\n",
            "[loading fbdialog data:/root/ParlAI/data/Persona-Chat/personachat/train_self_original.txt]\n",
            "[personachat]: your persona: i just started college.\n",
            "your persona: i have 3 science classes.\n",
            "your persona: i work part time in the campus library.\n",
            "your persona: i am living at home but hope to live in the dorms next year.\n",
            "hi how are you doing\n",
            "[labels: great ! just got off work and relaxing before i study]\n",
            "[label_candidates: yea . the piano . before i graduated college .|yes . very warm . i love it .|nice meeting you , spend as much time at home now that you can , i wish i could .|he was . he was my favorite artist .|i was . she was an addict though . love hate relationship . in the strongest way|...and 15 more]\n",
            "~~\n",
            "[personachat]: nice where do you work\n",
            "[labels: the library on campus , it is part time but really peaceful and easy]\n",
            "[label_candidates: that is amazing to hear . i like to run with my dogs .|i did not it was so yucky out|not too bad so far|i am a bowler and professional one and i have two kids and you ?|yes it could , i am always sad ugh , how are you ?|...and 15 more]\n",
            "~~\n",
            "[personachat]: that is cool i just live off my girlfriends salary\n",
            "[labels: i live at home , next year i want to move on campus though]\n",
            "[label_candidates: i wish i knew how to play .|hey , they call me blue eyes . do you have a nickname ?|are you going to cook for me ?|no i am currently taking my boards for pharmacy .|they can come too . the more the merrier .|...and 15 more]\n",
            "~~\n",
            "[personachat]: that is cool do you like to cook\n",
            "[labels: i do , i make this one dish with pork marinated in catalina dressing , its good]\n",
            "[label_candidates: i am doing well do you like music ?|i will check them out . i am really going to miss my sister when i move .|were they really ? i did not know that . i love to learn .|hi . i am alright . what do you like to do ? i am a writer .|me and my parents and brother moved here !|...and 15 more]\n",
            "~~\n",
            "[personachat]: that sounds so interesting i like to cook brunch on the weekends\n",
            "[labels: i do not cook a lot . this semester i have 3 different science classes]\n",
            "[label_candidates: wow that is interesting to hear|me too ! what do you do for a living ? i am in finance .|helping people . i guess that is why i am a nurse .|i enjoy going to park and bird watching . love country music|its not as fun as biking , but it pays the bills .|...and 15 more]\n",
            "~~\n",
            "[personachat]: wow is that your major ?\n",
            "[labels: chemistry , but have a minor in biology]\n",
            "[label_candidates: willie nelson , hank williams iii . . . . all the usual stuff . . . plus thrash metal from norway|very short . under 5 feet tall . trying to lose another 20 pounds ! it is hard !|new england is a beautiful place to grow up . i work in connecticut now . nice weather .|for what ? i know oliva pope personally . i have not been on a boat ever ? you ?|what do you do for a living ?|...and 15 more]\n",
            "~~\n",
            "[personachat]: wow what do you want to do after school\n",
            "[labels: ideally i want to work for an energy company working on new energy and fuel sources]\n",
            "[label_candidates: i have written several romance novels under a different name . . . .|do you have any pets ? my dog , socks , lives at my parents house .|what reality show do you like ? i am going to fail math because of dungeons and dragons .|shopping . it is like my passion .|i drop off baking goods in my state where i reside .|...and 15 more]\n",
            "~~\n",
            "[personachat]: cool i wish i knew more about science\n",
            "[labels: it is difficult but i do enjoy it , just takes a lot of studying]\n",
            "[label_candidates: i have three , and am named for my grandmother .|exactleee . . oops i am not great at spelling|black i guess . what about you ?|yes and sunset also is a good time|oh . i eat about anything .|...and 15 more]\n",
            "- - - - - - - - - - - - - - - - - - - - -\n",
            "~~\n",
            "[personachat]: your persona: i have borderline personality disorder.\n",
            "your persona: it is my universe , and everyone else is just a character in it.\n",
            "your persona: i work as a dental assistant in a ritzy part of town.\n",
            "your persona: at night , i party hard in the atlanta club scene , and i never miss a music festival.\n",
            "how are you doing today ?\n",
            "[labels: great ! just got back from some dbt therapy . it really helps me]\n",
            "[label_candidates: i am less afraid to drive as i am terrified of clowns though .|hi how are you today|rap and r b , i hate country tho|maybe you should find a job , i am looking for one , but nba is fun too|you must be a grown up .|...and 15 more]\n",
            "~~\n",
            "[personachat]: what is that ? i am not familiar .\n",
            "[labels: dialectical behavioral therapy . i use it to help with my borderline personality]\n",
            "[label_candidates: i have to hurry and clean up this mess if we are going to go out .|yes they are confused but not about being a boy or girl|princess from mario . what is your favorite song ?|i love texas i am going to live in australia next year for my boyfriend|wow that sounds interesting , my addiction to black coffee is out of control .|...and 15 more]\n",
            "~~\n",
            "[ loaded 8939 episodes with a total of 65719 examples ]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "V3Ob4tEt1vNP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 103
        },
        "outputId": "3950f757-cfbf-4e15-8bc1-8235132a3cdc"
      },
      "cell_type": "code",
      "source": [
        "%%html\n",
        "<p style='color: blue;'>\n",
        "  <b>Questions:</b>\n",
        "  <ul style='color: blue;'>\n",
        "    <li>What do the personalities look like?</li>\n",
        "    <li>How does creating bots with these simple personalities address consistency for chatbots? </li>\n",
        "    <li>What are some drawbacks/limitations of these specific personalities for addressing the problem of consistency?</li>\n",
        "  </ul>\n",
        "</p>"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style='color: blue;'>\n",
              "  <b>Questions:</b>\n",
              "  <ul style='color: blue;'>\n",
              "    <li>What do the personalities look like?</li>\n",
              "    <li>How does creating bots with these simple personalities address consistency for chatbots? </li>\n",
              "    <li>What are some drawbacks/limitations of these specific personalities for addressing the problem of consistency?</li>\n",
              "  </ul>\n",
              "</p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "Kyhri6NvYKda",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "***Let's understand how much data we have. Let's compute the following using ParlAI:***\n",
        "\n",
        "\n",
        "1.   **How many turns of data do we have?** In dialogue datasets, \"amount of data\" is measured in dialogue turns. Each time there is a single line of dialogue, that is called a \"turn\"\n",
        "2.   **On average, how many words form a model input?**\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "30SF6hN6DAjD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 425
        },
        "outputId": "f4a915b6-5d4f-4622-c995-cccf85dea0fc"
      },
      "cell_type": "code",
      "source": [
        "!python ~/ParlAI/parlai/scripts/data_stats.py -t personachat -dt train -ltim 10000"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[ note: changing datatype from train to train:ordered ]\n",
            "[creating task(s): personachat]\n",
            "[loading fbdialog data:/root/ParlAI/data/Persona-Chat/personachat/train_self_original.txt]\n",
            "[ loaded 8939 episodes with a total of 65719 examples ]\n",
            "24s elapsed: {'exs': 65719, '%done': '100.00%', 'time_left': '0s', 'stats': '\n",
            "input:\n",
            "   utterances: 65719\n",
            "   avg utterance length: 18.356974390967604\n",
            "   tokens: 1206402\n",
            "   unique tokens: 14209\n",
            "   unique utterances: 64580\n",
            "labels:\n",
            "   utterances: 65719\n",
            "   avg utterance length: 11.929411585690591\n",
            "   tokens: 783989\n",
            "   unique tokens: 14507\n",
            "   unique utterances: 64119\n",
            "both:\n",
            "   utterances: 131438\n",
            "   avg utterance length: 15.143192988329098\n",
            "   tokens: 1990391\n",
            "   unique tokens: 18741\n",
            "   unique utterances: 128197\n",
            "'}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "KpkwidfAZ_7p",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Models"
      ]
    },
    {
      "metadata": {
        "id": "YuqnjqxbZ_W2",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "As discussed in the lecture, there are two main kinds of dialogue models. \n",
        "\n",
        "*Retrieval* Models analyze the current dialogue context and try to find appropriate responses in the dataset.\n",
        "\n",
        "*Generative* Models analyze the current dialogue context\n",
        "and try to write an answer, word by word, from left to right.\n",
        "This can be thought of as an application of sequence-to-sequence models,  where the \"encoder side\" is the dialogue history and the \"decoder side\" is the dialogue response your chatbot should generate."
      ]
    },
    {
      "metadata": {
        "id": "JPRp1MlH3n0h",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        },
        "outputId": "48ad279b-35c7-41aa-b13a-a18734c3f480"
      },
      "cell_type": "code",
      "source": [
        "%%html\n",
        "<p style='color: blue;'>\n",
        "  <b>Questions:</b>\n",
        "  <ul style='color: blue;'>\n",
        "    <li>Review the pros/cons of retrieval compared to generative models - Are there settings when you might want to use one over the other?</li>\n",
        "    <li>Compare a chit-chat application to something like booking a movie ticket- would you want to use generative, retrieval, or something else to accomplish that task? Why?</li>\n",
        "  </ul>\n",
        "</p>"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style='color: blue;'>\n",
              "  <b>Questions:</b>\n",
              "  <ul style='color: blue;'>\n",
              "    <li>Review the pros/cons of retrieval compared to generative models - Are there settings when you might want to use one over the other?</li>\n",
              "    <li>Compare a chit-chat application to something like booking a movie ticket- would you want to use generative, retrieval, or something else to accomplish that task? Why?</li>\n",
              "  </ul>\n",
              "</p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "D_99CoAwaW2w",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Retrieval Models"
      ]
    },
    {
      "metadata": {
        "id": "BAfk4Km8bY_Y",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Let's train a model to do retrieval first. We will try the *Key-Value Memory Net.* "
      ]
    },
    {
      "metadata": {
        "id": "EyNOObOkbYTQ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# We can train a model with the following command: \n",
        "# !python ~/ParlAI/examples/train_model.py -m kv_memnn -t personachat -dt train -veps 0.25 --model-file persona_chat_retrieval_model -vmt accuracy\n",
        "\n",
        "# but we have limited time in the tutorial, so let's use an already pretrained model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "gylhJvZwa0Vp",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Quick Parameter Refresher:\n",
        "\n",
        "\n",
        "*  `-m ` means which model we're going to use. \"kv_memnn\" means the transformer architecture. Recall retrieval models are trained to rank the true response higher over a set of potential responses from the dataset (in ParlAI, these are called the \"label candidates\"). When it's time to write a dialogue response, the retrieval model returns the response that is ranked the highest\n",
        "*  -`t` refers to the task. Here, we are training on PersonaChat data.\n",
        "* `-dt` refers to the data split. We want to train our model, so we are using the training set.\n",
        "* `-veps` refers to how often we should evaluate during training, our performance on validation. recall this is important because models, particularly neural ones, have the capacity to memorize the training dataset. So it's important to check how the model is doing on the validation set.\n",
        "* `--model-file` refers to when your model is saved, what should the filename be\n",
        "*  `-vmt` refers to the metric which we'll use to decide which model is the best. We'll cover this in the next section\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "W6wdfxEccAAp",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Let's interact with the model to get a sense of what it's learning. **How is this chat going to work?\n",
        "\n",
        "\n",
        "\n",
        "1.   You will be assigned a persona. You will chat to the model by typing in the chat box.\n",
        "2.   The chatbot also has a persona. It's secret and hidden from you!\n",
        "3.   When you've finished chatting with this bot, type [DONE] and a new model persona will be assigned to the bot, so you can talk to a new bot. \n",
        "4.   When you move on to the next chatbot persona, the previous persona will be revealed. \n",
        "\n",
        "Interact with the chatbots and the personas. **Try to think about the following:**\n",
        "\n",
        "*   Do the chatbots follow their persona a lot?\n",
        "*   Was it difficult to follow your persona?\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "XdyaEgpcI7UL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2281
        },
        "outputId": "488cad52-e3e3-483f-afe2-736f52f8b3a6"
      },
      "cell_type": "code",
      "source": [
        "!python ~/ParlAI/projects/convai2/interactive.py -mf models:convai2/kvmemnn/model"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[building data: /root/ParlAI/data/models/convai2/kvmemnn/kvmemnn.tgz]\n",
            "[ downloading: http://parl.ai/downloads/_models/convai2/kvmemnn.tgz to /root/ParlAI/data/models/convai2/kvmemnn/kvmemnn.tgz ]\n",
            "Downloading kvmemnn.tgz: 100% 173M/173M [00:16<00:00, 10.5MB/s]\n",
            "unpacking kvmemnn.tgz\n",
            "[ warning: overriding opt['model_file'] to /root/ParlAI/data/models/convai2/kvmemnn/model (previously: /checkpoint/jase/20180328/kvmemnn_sweep10/persona-self_rephraseTrn-True_rephraseTst-False_lr-0.1_esz-2000_margin-0.1_tfidf-False_shareEmb-True_hops1_lins0/model )]\n",
            "[ creating KvmemnnAgent ]\n",
            "Dictionary: loading dictionary from /root/ParlAI/data/models/convai2/kvmemnn/model.dict\n",
            "[ num words =  19153 ]\n",
            "Loading existing model params from /root/ParlAI/data/models/convai2/kvmemnn/model\n",
            "[loading candidates: /root/ParlAI/data/models/convai2/kvmemnn/model.candspair*]\n",
            "[caching..]\n",
            "=init done=\n",
            "/usr/local/lib/python3.6/dist-packages/torch/nn/_reduction.py:49: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
            "  warnings.warn(warning.format(ret))\n",
            "[creating task(s): parlai.agents.local_human.local_human:LocalHumanAgent]\n",
            "[ optional arguments: ] \n",
            "[  display_examples: False ]\n",
            "[  display_ignore_fields: label_candidates,text_candidates ]\n",
            "[  display_prettify: False ]\n",
            "[ Main ParlAI Arguments: ] \n",
            "[  batchsize: 1 ]\n",
            "[  datapath: /private/home/jase/src/ParlAI/data ]\n",
            "[  datatype: train ]\n",
            "[  download_path: /private/home/jase/src/ParlAI/downloads ]\n",
            "[  hide_labels: False ]\n",
            "[  image_mode: raw ]\n",
            "[  multitask_weights: [1] ]\n",
            "[  numthreads: 40 ]\n",
            "[  show_advanced_args: False ]\n",
            "[  task: convai2:SelfRevisedTeacher ]\n",
            "[ ParlAI Model Arguments: ] \n",
            "[  dict_class: parlai.core.dict:DictionaryAgent ]\n",
            "[  init_model: None ]\n",
            "[  model: projects.personachat.kvmemnn.kvmemnn:KvmemnnAgent ]\n",
            "[  model_file: /root/ParlAI/data/models/convai2/kvmemnn/model ]\n",
            "[ Local Human Arguments: ] \n",
            "[  local_human_candidates_file: None ]\n",
            "[  single_turn: False ]\n",
            "[ ParlAI Image Preprocessing Arguments: ] \n",
            "[  image_cropsize: 224 ]\n",
            "[  image_size: 256 ]\n",
            "[creating task(s): convai2:both]\n",
            "[building data: /root/ParlAI/data/ConvAI2]\n",
            "[ downloading: http://parl.ai/downloads/convai2/convai2_fix_723.tgz to /root/ParlAI/data/ConvAI2/convai2_fix_723.tgz ]\n",
            "Downloading convai2_fix_723.tgz: 100% 430M/430M [00:37<00:00, 11.6MB/s]\n",
            "unpacking convai2_fix_723.tgz\n",
            "[loading fbdialog data:/root/ParlAI/data/ConvAI2/train_both_original.txt]\n",
            "your persona: my favorite is rock fish.\n",
            "your persona: i m going riding on my boat today.\n",
            "your persona: i love tuna.\n",
            "your persona: i live in cape hatteras.\n",
            "your persona: i'm a fisherman.\n",
            "Enter [DONE] if you want a new partner at any time.\n",
            "Enter Your Message: What are you doing next weekend?\n",
            "its good . and yours ? i was thinking of getting a dog at the shelter .\n",
            "Enter Your Message: How are you doing?\n",
            "i am fine just relaxing with my dog named toto\n",
            "Enter Your Message: I'm going fishing.\n",
            "i used to fish with my dad all the time before he passed . do you work ?\n",
            "Enter Your Message: Yeah, I am a fisherman.\n",
            "oh ok cool ! i love fishing as well been fishing since i was 5\n",
            "Enter Your Message: Cool! Do you work?\n",
            "i work at a fast food restaurant .\n",
            "Enter Your Message: [DONE]\n",
            "she is no good . find another\n",
            "CHAT DONE \n",
            "In case you were curious you were talking to this bot:\n",
            "['your persona: she taught me to cook.', 'your persona: she died when i was 18.', 'your persona: my mother is from russia.', 'your persona: i have a dog.', '']\n",
            "\n",
            "... preparing new chat... \n",
            "\n",
            "your persona: i'm a mom with two sons and a husband.\n",
            "your persona: my parents taught me to find inspiration in the world.\n",
            "your persona: i am an artist and create with my mind and my hands.\n",
            "your persona: since my dog died i am incomplete.\n",
            "your persona: i live in a house with a yard.\n",
            "Enter [DONE] if you want a new partner at any time.\n",
            "Enter Your Message: What are you doing this weekend? \n",
            "great , enjoying a break from my hectic schedule\n",
            "Enter Your Message: Cool, what do you work on?\n",
            "i am head researcher of french fries at del taco . you ?\n",
            "Enter Your Message: I'm an artist. \n",
            "have you ever written any songs ? i like to draw and paint on my free times .\n",
            "Enter Your Message: No, I don't know how to write songs. \n",
            "do you write a lot of it\n",
            "Enter Your Message: No\n",
            "oh . i am in high school . i am working on math now . thankfully its my favorite subject .\n",
            "Enter Your Message: [DONE]\n",
            "well i just got done with a worn jam sesh with friends . you like music ?\n",
            "CHAT DONE \n",
            "In case you were curious you were talking to this bot:\n",
            "[\"your persona: i've a friend group , but i don't like any of them.\", 'your persona: but , i feel lost and far away from who i truly am.', 'your persona: i coexist well with my husband.', \"your persona: i'm a middle aged mother of two high school boys.\", '']\n",
            "\n",
            "... preparing new chat... \n",
            "\n",
            "your persona: i like cooking healthy meals.\n",
            "your persona: i like to go out to the bars.\n",
            "your persona: i enjoy dating women.\n",
            "your persona: i am retired.\n",
            "your persona: i like to go to the gym and work out.\n",
            "Enter [DONE] if you want a new partner at any time.\n",
            "Enter Your Message: I like cooking. What about you?\n",
            "i love cooking but i do not have anyone to cook for but myself\n",
            "Enter Your Message: Oh, that's sad. I'm retired, so I get lonely sometimes.\n",
            "no siblings , no significant other means no drama . i like that and painting\n",
            "Enter Your Message: Cool, what do you paint?\n",
            "what do you like to paint ?\n",
            "Enter Your Message: That's what I said!\n",
            "when i was younger i was a huge superman\n",
            "Enter Your Message: [DONE]\n",
            "my sister is my twin\n",
            "CHAT DONE \n",
            "In case you were curious you were talking to this bot:\n",
            "['your persona: i have been cheated on by every ex girlfriend except for one.', 'your persona: there is only been one set of twins in my family.', 'your persona: i can make fart noises with my arm pits , even some musical melody.', 'your persona: i use to be a huge superman fan as a child.', '']\n",
            "\n",
            "... preparing new chat... \n",
            "\n",
            "your persona: i like to grow my own herbs and vegetables in my garden.\n",
            "your persona: my favorite food is raw onion.\n",
            "your persona: i have long curly hair.\n",
            "your persona: i m really into the powers of crystals.\n",
            "your persona: i sew my own clothes.\n",
            "Enter [DONE] if you want a new partner at any time.\n",
            "Enter Your Message: Traceback (most recent call last):\n",
            "  File \"/root/ParlAI/projects/convai2/interactive.py\", line 126, in <module>\n",
            "    interactive(parser.parse_args(print_args=False), print_parser=parser)\n",
            "  File \"/root/ParlAI/projects/convai2/interactive.py\", line 102, in interactive\n",
            "    acts[0] = agents[0].act()\n",
            "  File \"/root/ParlAI/parlai/agents/local_human/local_human.py\", line 39, in act\n",
            "    reply_text = input(\"Enter Your Message: \")\n",
            "KeyboardInterrupt\n",
            "^C\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "hNbf3YEp31Z0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        },
        "outputId": "37032d91-2aea-4085-b828-3d544fae02d9"
      },
      "cell_type": "code",
      "source": [
        "%%html\n",
        "<p style='color: blue;'>\n",
        "  <b>Questions:</b>\n",
        "  <ul style='color: blue;'>\n",
        "    <li>What does this model seem to be doing well? What is it doing poorly? </li>\n",
        "    <li>Why might it be performing poorly? What kind of experiment could you design to test your hypothesis? What baseline would you compare your experimental result with?</li>\n",
        "  </ul>\n",
        "</p>"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style='color: blue;'>\n",
              "  <b>Questions:</b>\n",
              "  <ul style='color: blue;'>\n",
              "    <li>What does this model seem to be doing well? What is it doing poorly? </li>\n",
              "    <li>Why might it be performing poorly? What kind of experiment could you design to test your hypothesis? What baseline would you compare your experimental result with?</li>\n",
              "  </ul>\n",
              "</p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "DaQ5x6TRcHox",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "We can try a more complex model as well. Let's try using the *Transformer Ranking* model. Unlike the KV-MemNN, the transformer ranker model uses the transformer architecture to encode the inputs. "
      ]
    },
    {
      "metadata": {
        "id": "-QaO8Nmm4W4X",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        },
        "outputId": "01389861-38b6-4272-eac1-7065ca6d0edc"
      },
      "cell_type": "code",
      "source": [
        "%%html\n",
        "<p style='color: blue;'>\n",
        "  <b>Questions:</b>\n",
        "  <ul style='color: blue;'>\n",
        "    <li>How do we know if we need to use a more complex model? Would we always want to use a more complex model? Why or why not?  </li>\n",
        "    <li>Why might the Transformer model have an advantage? What aspects of the architecture could make it good for this task? </li>\n",
        "  </ul>\n",
        "</p>"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style='color: blue;'>\n",
              "  <b>Questions:</b>\n",
              "  <ul style='color: blue;'>\n",
              "    <li>How do we know if we need to use a more complex model? Would we always want to use a more complex model? Why or why not?  </li>\n",
              "    <li>Why might the Transformer model have an advantage? What aspects of the architecture could make it good for this task? </li>\n",
              "  </ul>\n",
              "</p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "t_SYFM2UaUuq",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Here is a command to train a Transformer Ranker model\n",
        "# !python ~/ParlAI/examples/train_model.py -m transformer/ranker -t personachat -dt train -veps 0.25 --model-file persona_chat_retrieval_model -vmt accuracy\n",
        "\n",
        "# but let's use a pretrained one instead\n",
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Kd7Sfurfdc_3",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "An important aspect of training models is analyzing them. ***Try to answer the following questions.*** \n",
        "\n",
        "---\n",
        "\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "-1pAkQdt4n5_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 171
        },
        "outputId": "55d00f68-5327-483f-d90e-7c1aedd152ff"
      },
      "cell_type": "code",
      "source": [
        "%%html\n",
        "<p style='color: blue;'>\n",
        "  <b>Questions:</b>\n",
        "  <ul style='color: blue;'>\n",
        "    <li>Are the models using the persona that we have provided? How can you tell? If I asked you to prove it to me, what experiments could you conduct? </li>\n",
        "    <li>Previously, we computed some statistics about how long the persona is in the training data. The model has also only seen words present in the training dataset. But what happens if you push the model outside of what data it's been trained on? What kind of performance do you get? Why does this happen, and what could you do if you wanted to improve the model's ability to generalize? </li>\n",
        "    <li>We've trained some complex models to produce dialogues. In the lecture and previous lab, we saw some other, non-neural models that were evaluated as baselines. What kind of baseline models would you want to compare our two models against? Why? Which ones do you think would perform well?</li>\n",
        "    <li>In ParlAI, we've set the parameters to save the model's best performance based on validation accuracy. What would happen if we saved the model based on the best training accuracy? Why does this happen? (if you like, try this out on your own and see the effect when you interact with the bot)</li>\n",
        "  </ul>\n",
        "</p>"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style='color: blue;'>\n",
              "  <b>Questions:</b>\n",
              "  <ul style='color: blue;'>\n",
              "    <li>Are the models using the persona that we have provided? How can you tell? If I asked you to prove it to me, what experiments could you conduct? </li>\n",
              "    <li>Previously, we computed some statistics about how long the persona is in the training data. The model has also only seen words present in the training dataset. But what happens if you push the model outside of what data it's been trained on? What kind of performance do you get? Why does this happen, and what could you do if you wanted to improve the model's ability to generalize? </li>\n",
              "    <li>We've trained some complex models to produce dialogues. In the lecture and previous lab, we saw some other, non-neural models that were evaluated as baselines. What kind of baseline models would you want to compare our two models against? Why? Which ones do you think would perform well?</li>\n",
              "    <li>In ParlAI, we've set the parameters to save the model's best performance based on validation accuracy. What would happen if we saved the model based on the best training accuracy? Why does this happen? (if you like, try this out on your own and see the effect when you interact with the bot)</li>\n",
              "  </ul>\n",
              "</p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "eTHItY-QdNtw",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### [for self exploration] Generative Models"
      ]
    },
    {
      "metadata": {
        "id": "GM6LaBzbe6Za",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Generative models must produce word for word what they are going to say next in the dialogue. When predicting the next word, it produces a probability distribution over the entire vocabulary space for which word to generate next. To reduce the vocabulary space, we will use **byte-pair encoding** (BPE). \n",
        "\n",
        "*How does BPE work?* The BPE algorithm takes as input the training data and the number of *operations* it can do. It passes over the training set and tries to create sub-word units. For example, the word \"beautiful\" might be split into \"beau\" \"ti\" \"ful\". Each time it splits a word into sub-words, that is one operation. The final vocabulary output consists of these subwords. So \"ful\" can be part of \"beautiful\" and part of \"fruitful\" and so on.\n",
        "\n",
        "\n",
        "**Questions to ask yourself**:\n",
        "\n",
        "\n",
        "1.   Why is it important to keep the vocabulary space small?\n",
        "2.   What does perplexity measure? Why would we use it as a training objective? \n",
        "\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "G4gNbbAugACx",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!python ~/ParlAI/examples/train_model.py -m transformer/generator -t personachat -dt train -veps 0.25 --model-file persona_chat_generative_model -vmt ppl"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "fHpD0Ccb1zhd",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Final Thoughts"
      ]
    },
    {
      "metadata": {
        "id": "MHdsZ3Sq12n6",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**What did we learn about dialogue modeling? Review Questions to ask yourself**\n",
        "\n",
        "*   How do retrieval models work? What about generative? What are their pros and cons?\n",
        "*   What are some important traits of dialogue systems? How might the traits differ for different dialogue tasks?\n",
        "\n",
        "\n",
        "**General Takeaways about Machine Learning and Experimentation:**\n",
        "\n",
        "*   We don't try models just to try them - try to have a reason for conducting an experiment. As we did in the lab, try to analyze what's working well in your models and working poorly. Try to use these reasons to guide why you might want to try other models. Complex is not necessarily better. \n",
        "*   Certain models can be better for certain tasks. As we've seen, generative models are working really well for tasks such as machine translation, but have a bit to go before becoming general purpose dialogue generators. \n",
        "\n",
        "\n",
        "\n",
        "**I'm really interested in dialogue! What can I do to learn more?**\n",
        "\n",
        "\n",
        "*   Play around in ParlAI: ParlAI is a general library with many great dialogue models and code for them. It also provides a standard interface to access datasets and interact with various models. \n",
        "*   Read the PersonaChat Paper: https://arxiv.org/pdf/1801.07243.pdf\n",
        "\n",
        "\n"
      ]
    }
  ]
}