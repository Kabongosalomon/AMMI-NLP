{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchtext\n",
    "import torchtext.data as data\n",
    "from torchtext import vocab\n",
    "from collections import Counter\n",
    "import re\n",
    "from torchtext.data import TabularDataset \n",
    "import spacy\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import random\n",
    "import numpy\n",
    "import itertools\n",
    "from operator import itemgetter \n",
    "from glob import glob\n",
    "from tqdm import tqdm_notebook, tqdm\n",
    "from collections import Counter\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import string\n",
    "import re\n",
    "import more_itertools as mit  # not built-in package\n",
    "import torch\n",
    "import torchtext\n",
    "import torchtext.data as data\n",
    "from torchtext import vocab\n",
    "from collections import Counter\n",
    "import re\n",
    "from torchtext.data import TabularDataset\n",
    "\n",
    "class AmazonReviewsDataset(TabularDataset):\n",
    "    \n",
    "    urls = [\n",
    "           'http://snap.stanford.edu/data/amazon/productGraph/categoryFiles/reviews_Clothing_Shoes_and_Jewelry_5.json.gz',\n",
    "        ]\n",
    "    name='amazonreviews'\n",
    "    dirname='processed'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "RETOK = re.compile(r'\\w+|[^\\w\\s]|\\n', re.UNICODE)\n",
    "\n",
    "def tokenize(s):\n",
    "    return RETOK.findall(s)\n",
    "\n",
    "text_field = data.Field(sequential=True, tokenize=tokenize, include_lengths=True, use_vocab=True, lower=True, batch_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dataset = AmazonReviewsDataset(path='/home/roberta/ammi-2019-nlp/data/reviews_Clothing_Shoes_and_Jewelry_5.json', format='json', fields={'reviewText': ('reviewText', text_field), 'summary': ('summary', text_field)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "278677"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# convert the dataset to a list of strings\n",
    "# each string represents a review\n",
    "all_reviews = []\n",
    "for ex in dataset.examples:\n",
    "    all_reviews.append(ex.reviewText)\n",
    "len(all_reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "_tqdm = tqdm_notebook  # prolly you need jupyter widget for this, change for tqdm for simple tqdm\n",
    "\n",
    "frac = 1.0\n",
    "NUM_SENTENCES = int(frac*len(all_reviews))\n",
    "NUM_SENTENCES_TRAIN = int(0.8*NUM_SENTENCES)\n",
    "NUM_SENTENCES_VALID = int(0.1*NUM_SENTENCES)\n",
    "NUM_SENTENCES_TEST = NUM_SENTENCES - NUM_SENTENCES_TRAIN - NUM_SENTENCES_VALID\n",
    "\n",
    "train_reviews = all_reviews[:NUM_SENTENCES_TRAIN]\n",
    "test_reviews = all_reviews[NUM_SENTENCES_TRAIN:NUM_SENTENCES_TRAIN+NUM_SENTENCES_TEST]\n",
    "valid_reviews = all_reviews[NUM_SENTENCES_TRAIN+NUM_SENTENCES_TEST:NUM_SENTENCES_TRAIN+NUM_SENTENCES_TEST+NUM_SENTENCES_VALID]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(222941, 27867, 27869)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_reviews), len(valid_reviews), len(test_reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create .txt files with the reviews\n",
    "\n",
    "with open('../data/train.txt', 'w') as f:\n",
    "    for review in train_reviews:\n",
    "        for token in review:\n",
    "            f.write(\"%s \" % token) \n",
    "        f.write(\"\\n\")\n",
    "        \n",
    "with open('../data/test.txt', 'w') as f:\n",
    "    for review in test_reviews:\n",
    "        for token in review:\n",
    "            f.write(\"%s \" % token) \n",
    "        f.write(\"\\n\")\n",
    "        \n",
    "with open('../data/valid.txt', 'w') as f:\n",
    "    for review in valid_reviews:\n",
    "        for token in review:\n",
    "            f.write(\"%s \" % token) \n",
    "        f.write(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read data from .txt files and create lists of reviews\n",
    "train_data = []\n",
    "# create a list of all the reviews \n",
    "with open('../data/train.txt', 'r') as f:\n",
    "    train_data = [review for review in f.read().split('\\n') if review]\n",
    "    \n",
    "valid_data = []\n",
    "# create a list of all the reviews \n",
    "with open('../data/valid.txt', 'r') as f:\n",
    "    valid_data = [review for review in f.read().split('\\n') if review]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(\"this is a great tutu and at a really great price . it doesn ' t look cheap at all . i ' m so glad i looked on amazon and found such an affordable tutu that isn ' t made poorly . a + + \",\n",
       " list,\n",
       " 222919,\n",
       " str)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[0], valid_data[0]\n",
    "train_data = train_data#[:100]\n",
    "valid_data = valid_data#[:10]\n",
    "train_data[0], type(train_data), len(train_data), type(train_data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
