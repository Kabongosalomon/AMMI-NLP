{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Amazon review dataset routines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install stanfordnlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchtext\n",
    "import torchtext.data as data\n",
    "from torchtext import vocab\n",
    "from collections import Counter\n",
    "import re\n",
    "from torchtext.data import TabularDataset \n",
    "\n",
    "class AmazonReviewsDataset(TabularDataset):\n",
    "    \n",
    "    urls = [\n",
    "#            'http://snap.stanford.edu/data/amazon/productGraph/categoryFiles/reviews_Books_5.json.gz',\n",
    "#            'http://snap.stanford.edu/data/amazon/productGraph/categoryFiles/reviews_Electronics_5.json.gz',\n",
    "#            'http://snap.stanford.edu/data/amazon/productGraph/categoryFiles/reviews_Movies_and_TV_5.json.gz',\n",
    "#            'http://snap.stanford.edu/data/amazon/productGraph/categoryFiles/reviews_CDs_and_Vinyl_5.json.gz',\n",
    "#            'http://snap.stanford.edu/data/amazon/productGraph/categoryFiles/reviews_Clothing_Shoes_and_Jewelry_5.json.gz',\n",
    "#            'http://snap.stanford.edu/data/amazon/productGraph/categoryFiles/reviews_Home_and_Kitchen_5.json.gz',\n",
    "#            'http://snap.stanford.edu/data/amazon/productGraph/categoryFiles/reviews_Kindle_Store_5.json.gz',\n",
    "#            'http://snap.stanford.edu/data/amazon/productGraph/categoryFiles/reviews_Sports_and_Outdoors_5.json.gz',\n",
    "#            'http://snap.stanford.edu/data/amazon/productGraph/categoryFiles/reviews_Cell_Phones_and_Accessories_5.json.gz',\n",
    "#            'http://snap.stanford.edu/data/amazon/productGraph/categoryFiles/reviews_Health_and_Personal_Care_5.json.gz',\n",
    "#            'http://snap.stanford.edu/data/amazon/productGraph/categoryFiles/reviews_Toys_and_Games_5.json.gz',\n",
    "#            'http://snap.stanford.edu/data/amazon/productGraph/categoryFiles/reviews_Video_Games_5.json.gz',\n",
    "#            'http://snap.stanford.edu/data/amazon/productGraph/categoryFiles/reviews_Tools_and_Home_Improvement_5.json.gz',\n",
    "#            'http://snap.stanford.edu/data/amazon/productGraph/categoryFiles/reviews_Beauty_5.json.gz',\n",
    "#            'http://snap.stanford.edu/data/amazon/productGraph/categoryFiles/reviews_Apps_for_Android_5.json.gz',\n",
    "#            'http://snap.stanford.edu/data/amazon/productGraph/categoryFiles/reviews_Office_Products_5.json.gz',\n",
    "#            'http://snap.stanford.edu/data/amazon/productGraph/categoryFiles/reviews_Pet_Supplies_5.json.gz',\n",
    "#            'http://snap.stanford.edu/data/amazon/productGraph/categoryFiles/reviews_Automotive_5.json.gz',\n",
    "#            'http://snap.stanford.edu/data/amazon/productGraph/categoryFiles/reviews_Grocery_and_Gourmet_Food_5.json.gz',\n",
    "#            'http://snap.stanford.edu/data/amazon/productGraph/categoryFiles/reviews_Patio_Lawn_and_Garden_5.json.gz',\n",
    "#            'http://snap.stanford.edu/data/amazon/productGraph/categoryFiles/reviews_Baby_5.json.gz',\n",
    "#            'http://snap.stanford.edu/data/amazon/productGraph/categoryFiles/reviews_Digital_Music_5.json.gz',\n",
    "#            'http://snap.stanford.edu/data/amazon/productGraph/categoryFiles/reviews_Musical_Instruments_5.json.gz',\n",
    "            'http://snap.stanford.edu/data/amazon/productGraph/categoryFiles/reviews_Amazon_Instant_Video_5.json.gz',\n",
    "        ]\n",
    "    name='amazonreviews'\n",
    "    dirname='processed'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For now we download only one section, check class attribute 'urls' and uncomment if you want more\n",
    "\n",
    "I think we could jsut choose the most funny section there and it will be enough for us"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "download_done = AmazonReviewsDataset.download(root='data/', check=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Default tokenizer for data.Filed() is string.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "RETOK = re.compile(r'\\w+|[^\\w\\s]|\\n', re.UNICODE)\n",
    "\n",
    "def tokenize(s):\n",
    "    return RETOK.findall(s)\n",
    "\n",
    "text_field = data.Field(sequential=True, tokenize=tokenize, include_lengths=True, use_vocab=True, lower=True, batch_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = AmazonReviewsDataset(path='../data/amazonreviews/reviews_Amazon_Instant_Video_5.json', format='json', fields={'reviewText': ('reviewText', text_field), 'summary': ('summary', text_field)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples : 37126\n",
      "Review: \n",
      " ['i', 'had', 'big', 'expectations', 'because', 'i', 'love', 'english', 'tv', ',', 'in', 'particular', 'investigative', 'and', 'detective', 'stuff', 'but', 'this', 'guy', 'is', 'really', 'boring', '.', 'it', 'didn', \"'\", 't', 'appeal', 'to', 'me', 'at', 'all', '.'] \n",
      "\n",
      " Summary: \n",
      " ['a', 'little', 'bit', 'boring', 'for', 'me']\n"
     ]
    }
   ],
   "source": [
    "# lets check it\n",
    "# lets use fstrings btw\n",
    "print(f'Number of samples : {len(dataset.examples)}')\n",
    "\n",
    "for ex in dataset.examples:\n",
    "    print(f'Review: \\n {ex.reviewText} \\n\\n Summary: \\n {ex.summary}')\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fasttext vecs are about 6.6G, but I guess google colab has super fast link"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = vocab.FastText(language='en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "# building vocab file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_field.build_vocab(dataset, max_size=30000, vectors=out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "# making a batch iterator\n",
    "train_loader = data.BucketIterator(dataset=dataset, batch_size=4, sort_key=lambda x: len(x.reviewText), device=torch.device('cpu'), sort_within_batch=True, repeat=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[torchtext.data.batch.Batch of size 4 from AMAZONREVIEWS]\n",
      "\t[.reviewText]:('[torch.LongTensor of size 4x34]', '[torch.LongTensor of size 4]')\n",
      "\t[.summary]:('[torch.LongTensor of size 4x9]', '[torch.LongTensor of size 4]')\n"
     ]
    }
   ],
   "source": [
    "batch = next(iter(train_loader))\n",
    "print(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _vec2txt(vec):\n",
    "    return [text_field.vocab.itos[t] for t in vec]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([   46,  1923,     8,  2034, 24716,     2,   282,     7,   339,     3,\n",
      "          454,   101,  1495,   120,    35,   173,   454,   140,    22,    26,\n",
      "           61,   510,     6,   170,    66,     3,   325,     8,     3,   936,\n",
      "           14,    13,    39,     2])\n",
      "['great', 'variety', 'of', 'items', 'pawned', '.', 'hard', 'to', 'believe', 'the', 'money', 'people', 'loose', 'because', 'they', 'want', 'money', 'now', '!', 'you', 'can', 'learn', 'a', 'lot', 'about', 'the', 'history', 'of', 'the', 'south', 'in', 'this', 'one', '.']\n"
     ]
    }
   ],
   "source": [
    "print(batch.reviewText[0][0])\n",
    "print(_vec2txt(batch.reviewText[0][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
