{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/kyunghyuncho/ammi-2019-nlp/blob/master/01-day-LM/ngram_lm.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Language Modeling\n",
    "\n",
    "### Goal: compute a probabilty distribution over all possible sentences:\n",
    "\n",
    "\n",
    "### $$p(W) = p(w_1, w_2, ..., w_T)$$\n",
    "\n",
    "### This unsupervised learning problem can be framed as a sequence of supervised learning problems:\n",
    "\n",
    "### $$p(W) = p(w_1) * p(w_2|w_1) * ... * p(w_T|w_1, ..., w_{T-1})$$\n",
    "\n",
    "### If we have K sentences, where the j-th sentence has T_j words for all j frmo 1 to K, then we want to max:\n",
    "\n",
    "### $$log p(W) = \\sum_{j = 1}^K \\sum_{i=1}^{T_j} log p(w_i | w_{<i})$$\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# N-gram language model\n",
    "\n",
    "### Goal: estimate the n-gram probabilities using counts of sequences of n consecutive words\n",
    "\n",
    "### Given a sequence of words $w$, we want to compute\n",
    "\n",
    "###  $$P(w_i|w_{i−1}, w_{i−2}, …, w_{i−n+1})$$\n",
    "\n",
    "### Where $w_i$ is the i-th word of the sequence.\n",
    "\n",
    "### $$P(w_i|w_{i−n+1}, ..., w_{i−2}, w_{i−1}) = \\frac{p(w_{i−n+1}, ..., w_{i−2}, w_{i−1}, w_i)}{\\sum_{w \\in V} p(w_{i−n+1}, ..., w_{i−2}, w_{i−1}, w)}$$\n",
    "\n",
    "### Key Idea: We can estimate the probabilities using counts of n-grams in our dataset \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## N-gram Probabilities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## $$P(w_i|w_{i−n+1}, ..., w_{i−2}, w_{i−1}) \\approx \\frac{c(w_{i−n+1}, ..., w_{i−2}, w_{i−1}, w_i)}{\\sum_{w \\in V} c(w_{i−n+1}, ..., w_{i−2}, w_{i−1}, w)}$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bigram Probabilities\n",
    "\n",
    "## $$p(w_i | w_{i-1}) = \\frac{c(w_{i-1}, w_i)}{\\sum_{w_i} c(w_{i-1}, w_i)} $$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting en_core_web_sm==2.0.0 from https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.0.0/en_core_web_sm-2.0.0.tar.gz#egg=en_core_web_sm==2.0.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.0.0/en_core_web_sm-2.0.0.tar.gz (37.4MB)\n",
      "\u001b[K    100% |████████████████████████████████| 37.4MB 981kB/s \n",
      "\u001b[?25hInstalling collected packages: en-core-web-sm\n",
      "  Running setup.py install for en-core-web-sm ... \u001b[?25lerror\n",
      "    Complete output from command /home/kulikov/venv/ammi/bin/python -u -c \"import setuptools, tokenize;__file__='/tmp/pip-build-1w10f_lh/en-core-web-sm/setup.py';f=getattr(tokenize, 'open', open)(__file__);code=f.read().replace('\\r\\n', '\\n');f.close();exec(compile(code, __file__, 'exec'))\" install --record /tmp/pip-l0j0sy9u-record/install-record.txt --single-version-externally-managed --compile --install-headers /home/kulikov/venv/ammi/include/site/python3.5/en-core-web-sm:\n",
      "    running install\n",
      "    running build\n",
      "    running build_py\n",
      "    creating build\n",
      "    creating build/lib\n",
      "    creating build/lib/en_core_web_sm\n",
      "    copying en_core_web_sm/__init__.py -> build/lib/en_core_web_sm\n",
      "    creating build/lib/en_core_web_sm/en_core_web_sm-2.0.0\n",
      "    copying en_core_web_sm/en_core_web_sm-2.0.0/tokenizer -> build/lib/en_core_web_sm/en_core_web_sm-2.0.0\n",
      "    copying en_core_web_sm/en_core_web_sm-2.0.0/accuracy.json -> build/lib/en_core_web_sm/en_core_web_sm-2.0.0\n",
      "    copying en_core_web_sm/en_core_web_sm-2.0.0/meta.json -> build/lib/en_core_web_sm/en_core_web_sm-2.0.0\n",
      "    creating build/lib/en_core_web_sm/en_core_web_sm-2.0.0/tagger\n",
      "    copying en_core_web_sm/en_core_web_sm-2.0.0/tagger/cfg -> build/lib/en_core_web_sm/en_core_web_sm-2.0.0/tagger\n",
      "    copying en_core_web_sm/en_core_web_sm-2.0.0/tagger/model -> build/lib/en_core_web_sm/en_core_web_sm-2.0.0/tagger\n",
      "    copying en_core_web_sm/en_core_web_sm-2.0.0/tagger/tag_map -> build/lib/en_core_web_sm/en_core_web_sm-2.0.0/tagger\n",
      "    creating build/lib/en_core_web_sm/en_core_web_sm-2.0.0/parser\n",
      "    copying en_core_web_sm/en_core_web_sm-2.0.0/parser/cfg -> build/lib/en_core_web_sm/en_core_web_sm-2.0.0/parser\n",
      "    copying en_core_web_sm/en_core_web_sm-2.0.0/parser/lower_model -> build/lib/en_core_web_sm/en_core_web_sm-2.0.0/parser\n",
      "    copying en_core_web_sm/en_core_web_sm-2.0.0/parser/upper_model -> build/lib/en_core_web_sm/en_core_web_sm-2.0.0/parser\n",
      "    copying en_core_web_sm/en_core_web_sm-2.0.0/parser/moves -> build/lib/en_core_web_sm/en_core_web_sm-2.0.0/parser\n",
      "    copying en_core_web_sm/en_core_web_sm-2.0.0/parser/tok2vec_model -> build/lib/en_core_web_sm/en_core_web_sm-2.0.0/parser\n",
      "    creating build/lib/en_core_web_sm/en_core_web_sm-2.0.0/ner\n",
      "    copying en_core_web_sm/en_core_web_sm-2.0.0/ner/cfg -> build/lib/en_core_web_sm/en_core_web_sm-2.0.0/ner\n",
      "    copying en_core_web_sm/en_core_web_sm-2.0.0/ner/lower_model -> build/lib/en_core_web_sm/en_core_web_sm-2.0.0/ner\n",
      "    copying en_core_web_sm/en_core_web_sm-2.0.0/ner/upper_model -> build/lib/en_core_web_sm/en_core_web_sm-2.0.0/ner\n",
      "    copying en_core_web_sm/en_core_web_sm-2.0.0/ner/moves -> build/lib/en_core_web_sm/en_core_web_sm-2.0.0/ner\n",
      "    copying en_core_web_sm/en_core_web_sm-2.0.0/ner/tok2vec_model -> build/lib/en_core_web_sm/en_core_web_sm-2.0.0/ner\n",
      "    creating build/lib/en_core_web_sm/en_core_web_sm-2.0.0/vocab\n",
      "    copying en_core_web_sm/en_core_web_sm-2.0.0/vocab/strings.json -> build/lib/en_core_web_sm/en_core_web_sm-2.0.0/vocab\n",
      "    copying en_core_web_sm/en_core_web_sm-2.0.0/vocab/key2row -> build/lib/en_core_web_sm/en_core_web_sm-2.0.0/vocab\n",
      "    copying en_core_web_sm/en_core_web_sm-2.0.0/vocab/vectors -> build/lib/en_core_web_sm/en_core_web_sm-2.0.0/vocab\n",
      "    copying en_core_web_sm/en_core_web_sm-2.0.0/vocab/lexemes.bin -> build/lib/en_core_web_sm/en_core_web_sm-2.0.0/vocab\n",
      "    copying en_core_web_sm/meta.json -> build/lib/en_core_web_sm\n",
      "    running install_lib\n",
      "    creating /home/kulikov/venv/ammi/lib/python3.5/site-packages/en_core_web_sm\n",
      "    error: could not create '/home/kulikov/venv/ammi/lib/python3.5/site-packages/en_core_web_sm': Permission denied\n",
      "    \n",
      "    ----------------------------------------\n",
      "\u001b[31mCommand \"/home/kulikov/venv/ammi/bin/python -u -c \"import setuptools, tokenize;__file__='/tmp/pip-build-1w10f_lh/en-core-web-sm/setup.py';f=getattr(tokenize, 'open', open)(__file__);code=f.read().replace('\\r\\n', '\\n');f.close();exec(compile(code, __file__, 'exec'))\" install --record /tmp/pip-l0j0sy9u-record/install-record.txt --single-version-externally-managed --compile --install-headers /home/kulikov/venv/ammi/include/site/python3.5/en-core-web-sm\" failed with error code 1 in /tmp/pip-build-1w10f_lh/en-core-web-sm/\u001b[0m\n",
      "\u001b[?25h"
     ]
    }
   ],
   "source": [
    "# !python -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "[E050] Can't find model 'en_core_web_sm'. It doesn't seem to be a shortcut link, a Python package or a valid path to a data directory.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-7215d1f4f788>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'utils/'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mngram_utils\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mngram_utils\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mglobal_variables\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mgl\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/ammi-2019-nlp/01-day-LM/utils/ngram_utils.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;31m# Load English tokenizer, tagger, parser, NER and word vectors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m \u001b[0mtokenizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mspacy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'en_core_web_sm'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0mpunctuations\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'\"#$%&\\()*+-/:;<=>@[\\\\]^_`{|}~'\u001b[0m   \u001b[0;31m# kept ' , . ? !\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/kulikov/venv/ammi/lib/python3.5/site-packages/spacy/__init__.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(name, **overrides)\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mdepr_path\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0mdeprecation_warning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mWarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mW001\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdepr_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0moverrides\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/kulikov/venv/ammi/lib/python3.5/site-packages/spacy/util.py\u001b[0m in \u001b[0;36mload_model\u001b[0;34m(name, **overrides)\u001b[0m\n\u001b[1;32m    117\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'exists'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# Path or Path-like to model data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mload_model_from_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0moverrides\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 119\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mIOError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mErrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mE050\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    120\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mOSError\u001b[0m: [E050] Can't find model 'en_core_web_sm'. It doesn't seem to be a shortcut link, a Python package or a valid path to a data directory."
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append('utils/')\n",
    "from utils import ngram_utils as ngram_utils\n",
    "import utils.global_variables as gl\n",
    "import torch\n",
    "import random\n",
    "from utils.ngram_utils import NgramLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "H20pktPiA63a",
    "outputId": "fb38d897-e889-4451-df77-9ca98eb266a5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f2bc31fd2b0>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data from .txt Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read data from .txt files and create lists of reviews\n",
    "\n",
    "train_data = []\n",
    "# create a list of all the reviews \n",
    "with open('../data/amazon_train.txt', 'r') as f:\n",
    "    train_data = [review for review in f.read().split('\\n') if review]\n",
    "    \n",
    "valid_data = []\n",
    "# create a list of all the reviews \n",
    "with open('../data/amazon_valid.txt', 'r') as f:\n",
    "    valid_data = [review for review in f.read().split('\\n') if review]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# type(train_data), len(train_data), \\\n",
    "# type(train_data[0]), len(train_data[0]), \\\n",
    "# type(train_data[0][0]), len(train_data[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(\"this is a great tutu and at a really great price . it doesn ' t look cheap at all . i ' m so glad i looked on amazon and found such an affordable tutu that isn ' t made poorly . a + + \",\n",
       " 't',\n",
       " 22288)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[0], train_data[0][0], len(train_data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Process the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "45f6691ab7784eb79c145542dc9dd419",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f95946ac0ba849a3bbaf5be56a3eace2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Tokenize the Datasets\n",
    "# TODO: this takes a really long time !! why?\n",
    "train_data_tokenized, all_tokens_train = ngram_utils.tokenize_dataset(train_data)\n",
    "valid_data_tokenized, all_tokens_valid = ngram_utils.tokenize_dataset(valid_data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at the tokenized data!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(107790,\n",
       " ['this',\n",
       "  'is',\n",
       "  'a',\n",
       "  'great',\n",
       "  'tutu',\n",
       "  'and',\n",
       "  'at',\n",
       "  'a',\n",
       "  'really',\n",
       "  'great',\n",
       "  'price',\n",
       "  '.'])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # Number of All Tokens\n",
    "# len(all_tokens_train), all_tokens_train[0], \\\n",
    "len(train_data_tokenized), train_data_tokenized[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ngram_lm = NgramLM(train_data_tokenized, all_tokens_train, n=3, smoothing=None)\n",
    "valid_ngram_lm = NgramLM(valid_data_tokenized, all_tokens_valid, n=3, smoothing=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "96175"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ngram_lm.trie_ngram['./<eos>/<eos>']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 0.9)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ngram_lm.n, train_ngram_lm.frac_vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<unk>', '<sos>', '<eos>', '.', 'the', 'i', ',', 'and', 'a', 'it']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_ngram_lm.id2token[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 1, 4)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_ngram_lm.token2id['<unk>'], valid_ngram_lm.token2id['<sos>'], valid_ngram_lm.token2id['the']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((('.', '<eos>', '<eos>'),\n",
       "  ('<sos>', '<sos>', 'i'),\n",
       "  ('<sos>', '<sos>', 'the'),\n",
       "  ('<sos>', '<sos>', 'it'),\n",
       "  ('!', '<eos>', '<eos>'),\n",
       "  ('<sos>', '<sos>', 'this'),\n",
       "  ('it', \"'\", 's'),\n",
       "  ('.', '.', '.'),\n",
       "  ('.', '.', '<eos>'),\n",
       "  ('<sos>', '<sos>', 'they')),\n",
       " (13625, 3635, 1425, 1100, 1049, 762, 687, 655, 580, 569))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_ngram_lm.vocab_ngram[:10], valid_ngram_lm.count_ngram[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((('.', '<eos>'),\n",
       "  ('<sos>', 'i'),\n",
       "  ('<sos>', 'the'),\n",
       "  (\"'\", 't'),\n",
       "  (\"'\", 's'),\n",
       "  ('.', '.'),\n",
       "  ('<sos>', 'it'),\n",
       "  ('!', '<eos>'),\n",
       "  (',', 'and'),\n",
       "  (',', 'but')),\n",
       " (13625, 3635, 1425, 1261, 1249, 1238, 1100, 1049, 900, 838))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_ngram_lm.vocab_bigram[:10], valid_ngram_lm.count_bigram[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((('.',),\n",
       "  ('the',),\n",
       "  ('i',),\n",
       "  (',',),\n",
       "  ('and',),\n",
       "  ('a',),\n",
       "  ('it',),\n",
       "  ('to',),\n",
       "  (\"'\",),\n",
       "  ('is',)),\n",
       " (14883, 9408, 8000, 7525, 6226, 5774, 5085, 4550, 3816, 3695))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_ngram_lm.vocab_unigram[:10], valid_ngram_lm.count_unigram[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((('.', '<eos>'),\n",
       "  ('<sos>', 'i'),\n",
       "  ('<sos>', 'the'),\n",
       "  (\"'\", 't'),\n",
       "  (\"'\", 's'),\n",
       "  ('.', '.'),\n",
       "  ('<sos>', 'it'),\n",
       "  ('!', '<eos>'),\n",
       "  (',', 'and'),\n",
       "  (',', 'but')),\n",
       " (13625, 3635, 1425, 1261, 1249, 1238, 1100, 1049, 900, 838))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_ngram_lm.vocab_prev_ngram[:10], valid_ngram_lm.count_prev_ngram[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('.', '<eos>', '<eos>'),\n",
       " ('<sos>', '<sos>', 'i'),\n",
       " ('<sos>', '<sos>', 'the'),\n",
       " ('<sos>', '<sos>', 'it'),\n",
       " ('!', '<eos>', '<eos>'),\n",
       " ('<sos>', '<sos>', 'this'),\n",
       " ('it', \"'\", 's'),\n",
       " ('.', '.', '.'),\n",
       " ('.', '.', '<eos>'),\n",
       " ('<sos>', '<sos>', 'they')]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_ngram_lm.id2token_ngram[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 8)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_ngram_lm.token2id_ngram[('.', '<eos>', '<eos>')], valid_ngram_lm.token2id_ngram[('.', '.', '<eos>')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Build the Vocabulary \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word vocabulary size: 20806 words\n"
     ]
    }
   ],
   "source": [
    "# Build a vocabulary using all the tokens found in train data (90% of most common ones)\n",
    "print('Word vocabulary size: {} words'.format(len(train_ngram_lm.token2id)))        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CORPUS ANALYSIS (Train + Valid Data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Number of Tokens in the Corpus Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of All Tokens  1623446\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of All Tokens \", len(all_tokens_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Number of Sentences in the Train Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Sentences  107790\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of Sentences \", len(train_ngram_lm.raw_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## N-grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 3 # trigrams"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function for padding the sentences with special markers sentence beginning and end, i.e. $<bos>$ and $<eos>$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_padded = train_ngram_lm.padded_data\n",
    "train_ngram = train_ngram_lm.ngram_data\n",
    "vocab_ngram = train_ngram_lm.vocab_ngram\n",
    "count_ngram = train_ngram_lm.count_ngram "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<sos>',\n",
       " '<sos>',\n",
       " 'this',\n",
       " 'is',\n",
       " 'a',\n",
       " 'great',\n",
       " 'tutu',\n",
       " 'and',\n",
       " 'at',\n",
       " 'a',\n",
       " 'really',\n",
       " 'great',\n",
       " 'price',\n",
       " '.',\n",
       " '<eos>',\n",
       " '<eos>']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_padded[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function for finding all N-grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('<sos>', '<sos>', 'this'),\n",
       " ('<sos>', 'this', 'is'),\n",
       " ('this', 'is', 'a'),\n",
       " ('is', 'a', 'great'),\n",
       " ('a', 'great', 'tutu'),\n",
       " ('great', 'tutu', 'and'),\n",
       " ('tutu', 'and', 'at'),\n",
       " ('and', 'at', 'a'),\n",
       " ('at', 'a', 'really'),\n",
       " ('a', 'really', 'great'),\n",
       " ('really', 'great', 'price'),\n",
       " ('great', 'price', '.'),\n",
       " ('price', '.', '<eos>'),\n",
       " ('.', '<eos>', '<eos>')]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ngram[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('.', '<eos>', '<eos>')"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_ngram[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "96175"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_ngram[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "trie_ngram = train_ngram_lm.trie_ngram\n",
    "# trie_ngram\n",
    "# trie_prev_ngram = train_ngram_lm.trie_prev_ngram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "96175"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trie_ngram['./<eos>/<eos>']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "id2token = train_ngram_lm.id2token\n",
    "token2id = train_ngram_lm.token2id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "id2token_ngram = train_ngram_lm.id2token_ngram\n",
    "token2id_ngram = train_ngram_lm.token2id_ngram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token id 669138 ; token ('little', 'necklace', 'for')\n",
      "Token ('little', 'necklace', 'for'); token id 669138\n"
     ]
    }
   ],
   "source": [
    "random_token_id = random.randint(0, len(id2token_ngram) - 1)\n",
    "random_token = id2token_ngram[random_token_id]\n",
    "\n",
    "print (\"Token id {} ; token {}\".format(random_token_id, id2token_ngram[random_token_id]))\n",
    "print (\"Token {}; token id {}\".format(random_token, token2id_ngram[random_token]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ngram Count & Probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: print the words for which the pd is nonzero !!! -- more intuitive than a list of numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((('.', '<eos>', '<eos>'),\n",
       "  ('<sos>', '<sos>', 'i'),\n",
       "  ('<sos>', '<sos>', 'the'),\n",
       "  ('!', '<eos>', '<eos>'),\n",
       "  ('<sos>', '<sos>', 'they'),\n",
       "  ('<sos>', '<sos>', 'it'),\n",
       "  ('.', '.', '.'),\n",
       "  ('<sos>', '<sos>', 'this'),\n",
       "  ('<sos>', '<sos>', 'these'),\n",
       "  ('.', '.', '<eos>')),\n",
       " (96175, 26986, 9197, 8152, 6376, 5373, 4693, 4189, 3941, 3876))"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_ngram[:10], count_ngram[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 0.04, 0.04, 0.04, 0.0, 1.0)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c = train_ngram_lm.get_ngram_count(('an', 'older', 'coat'))\n",
    "p = train_ngram_lm.get_ngram_prob(('an', 'older', 'coat'))\n",
    "\n",
    "p1 = train_ngram_lm.get_ngram_prob(('an', 'older', 'pc'))\n",
    "p2 = train_ngram_lm.get_ngram_prob(('an', 'older', 'lady'))\n",
    "p3 = train_ngram_lm.get_ngram_prob(('an', 'older', 'watch'))\n",
    "\n",
    "pd = train_ngram_lm.get_prob_distr_ngram(('an', 'older'))\n",
    "\n",
    "c, p, p1, p2, p3, sum(pd)#, pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 0.06521739130434782, 1.0)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c = train_ngram_lm.get_ngram_count(('really', 'great', 'price'))\n",
    "p = train_ngram_lm.get_ngram_prob(('really', 'great', 'price'))\n",
    "pd = train_ngram_lm.get_prob_distr_ngram(('really', 'great'))\n",
    "\n",
    "c, p, sum(pd)#, pd "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c = train_ngram_lm.get_ngram_count(('really', 'great'))\n",
    "\n",
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(96175, 1.0, 1.0)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c = train_ngram_lm.get_ngram_count(('.', '<eos>', '<eos>'))\n",
    "p = train_ngram_lm.get_ngram_prob(('.', '<eos>', '<eos>'))\n",
    "pd = train_ngram_lm.get_prob_distr_ngram(('.', '<eos>'))\n",
    "\n",
    "c, p, sum(pd)#, pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c = train_ngram_lm.get_ngram_count(('.', '<sos>', '<sos>'))\n",
    "\n",
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 0, 0.9999999999999897)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c = train_ngram_lm.get_ngram_count(('i', 'like', 'pandas'))\n",
    "p = train_ngram_lm.get_ngram_count(('i', 'like', 'pandas'))\n",
    "pd = train_ngram_lm.get_prob_distr_ngram(('i', 'like'))\n",
    "\n",
    "c, p, sum(pd)#, pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(266, 0.09761467889908257, 1.0000000000000142)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c = train_ngram_lm.get_ngram_count(('is', 'a', 'great'))\n",
    "p = train_ngram_lm.get_ngram_prob(('is', 'a', 'great'))\n",
    "pd = train_ngram_lm.get_prob_distr_ngram(('is', 'a'))\n",
    "\n",
    "c, p, sum(pd)#, pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28, 0.9032258064516129, 1.0000000000000657)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c = train_ngram_lm.get_ngram_count(('send', 'it', 'back'))\n",
    "p = train_ngram_lm.get_ngram_prob(('send', 'it', 'back'))\n",
    "pd = train_ngram_lm.get_prob_distr_ngram(('send', 'it', 'back'))\n",
    "\n",
    "c, p, sum(pd)#, pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 0, 1.0000000000000657)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c = train_ngram_lm.get_ngram_count(('i', 'like', 'these', 'pictures'))\n",
    "p = train_ngram_lm.get_ngram_prob(('i', 'like', 'these', 'pictures'))\n",
    "pd = train_ngram_lm.get_prob_distr_ngram(('i', 'like', 'these'))\n",
    "\n",
    "c, p, sum(pd)#, pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add-One Smoothing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## $$P(w_i|w_{i−n+1}, ..., w_{i−2}, w_{i−1}) \\approx \\frac{1 + c(w_{i−n+1}, ..., w_{i−2}, w_{i−1}, w_i)}{\\mid V\\mid + \\sum_{w \\in V} c(w_{i−n+1}, ..., w_{i−2}, w_{i−1}, w)}$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.806305873305777e-05"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = train_ngram_lm.get_ngram_prob_add_one_smoothing(('.', '<sos>', '<sos>'))\n",
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.504098729844158e-05"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = train_ngram_lm.get_ngram_prob_add_one_smoothing(('i', 'like', 'pandas'))\n",
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.004323934780650392"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = train_ngram_lm.get_ngram_prob_add_one_smoothing(('i', 'like', 'this'))\n",
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0001918281220026856"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = train_ngram_lm.get_ngram_prob_add_one_smoothing(('really', 'great', 'price'))\n",
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0013917550511110045"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = train_ngram_lm.get_ngram_prob_add_one_smoothing(('send', 'it', 'back'))\n",
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8221506056539096"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = train_ngram_lm.get_ngram_prob_add_one_smoothing(('.', '<eos>', '<eos>'))\n",
    "p"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Additive Smoothing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## $$P(w_i|w_{i−n+1}, ..., w_{i−2}, w_{i−1}) \\approx \\frac{\\delta + c(w_{i−n+1}, ..., w_{i−2}, w_{i−1}, w_i)}{\\delta\\mid V\\mid + \\sum_{w \\in V} c(w_{i−n+1}, ..., w_{i−2}, w_{i−1}, w)}$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.806305873305777e-05"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = train_ngram_lm.get_ngram_prob_additive_smoothing(('.', '<sos>', '<sos>'), delta = 0.5)\n",
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.237647258242224e-05"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = train_ngram_lm.get_ngram_prob_additive_smoothing(('i', 'like', 'pandas'), delta = 0.5)\n",
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.008093906263242648"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = train_ngram_lm.get_ngram_prob_additive_smoothing(('i', 'like', 'this'), delta = 0.5)\n",
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.00033496028328069673"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = train_ngram_lm.get_ngram_prob_additive_smoothing(('really', 'great', 'price'), delta = 0.5)\n",
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0027314548591144336"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = train_ngram_lm.get_ngram_prob_additive_smoothing(('send', 'it', 'back'), delta = 0.5)\n",
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9023954287001069"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = train_ngram_lm.get_ngram_prob_additive_smoothing(('.', '<eos>', '<eos>'), delta = 0.5)\n",
    "p"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Changing the Parameter $\\delta$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9788256343658784"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# small delta --> closer to no smoothing  (1.0)\n",
    "p = train_ngram_lm.get_ngram_prob_additive_smoothing(('.', '<eos>', '<eos>'), delta = 0.1)\n",
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8370371208455323"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# arge delta --> closer to add-one smoothing (0.58)\n",
    "p = train_ngram_lm.get_ngram_prob_additive_smoothing(('.', '<eos>', '<eos>'), delta = 0.9)\n",
    "p"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Interpolation Smoothing (Jelinek-Mercer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### $$P(w_i|w_{i−n+1}, ..., w_{i−2}, w_{i−1}) \\approx \\alpha_n P(w_i|w_{i−n+1}, ..., w_{i−2}, w_{i−1}) + (1 - \\alpha_n) P(w|w_{i−n+2}, ..., w_{i−2}, w_{i−1})$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = train_ngram_lm.get_ngram_prob_interpolation_smoothing(('.', '<sos>', '<sos>'), alpha = 0.8)\n",
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = train_ngram_lm.get_ngram_prob_interpolation_smoothing(('i', 'like', 'pandas'), alpha = 0.8)\n",
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.054441260744985676"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = train_ngram_lm.get_ngram_prob_interpolation_smoothing(('i', 'like', 'this'), alpha = 0.8)\n",
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.052173913043478265"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = train_ngram_lm.get_ngram_prob_interpolation_smoothing(('really', 'great', 'price'), alpha = 0.8)\n",
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7225806451612904"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = train_ngram_lm.get_ngram_prob_interpolation_smoothing(('send', 'it', 'back'), alpha = 0.8)\n",
    "p"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Changing the Parameter $\\alpha$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# small delta --> closer to no smoothing  (1.0)\n",
    "p = train_ngram_lm.get_ngram_prob_interpolation_smoothing(('.', '<eos>', '<eos>'), alpha = 0.8)\n",
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# small delta --> closer to no smoothing  (1.0)\n",
    "p = train_ngram_lm.get_ngram_prob_interpolation_smoothing(('.', '<eos>', '<eos>'), alpha = 0.5)\n",
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# small delta --> closer to no smoothing  (1.0)\n",
    "p = train_ngram_lm.get_ngram_prob_interpolation_smoothing(('.', '<eos>', '<eos>'), alpha = 0.2)\n",
    "p"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Interpolation with Absolute Discounting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### $$p_{bi}(w|v) = max ({ \\frac{N(v, w) - b_{bi}}{N(v)}, 0)  + b_{bi} \\frac{V - N_0(v, \\cdot)}{N(v)} p_{uni}(w) \\large}$$\n",
    "\n",
    "### $$p_{uni}(w) = max ({ \\frac{N(w) - b_{uni}}{N}, 0)  + b_{uni} \\frac{V - N_0(\\cdot)}{N} \\frac{1}{V}}$$\n",
    "\n",
    "### $$b_{bi} = \\frac{N_1(\\cdot, \\cdot)}{N_1(\\cdot, \\cdot) + 2*N_2(\\cdot, \\cdot)}$$\n",
    "\n",
    "### $$b_{uni} = \\frac{N_1(\\cdot)}{N_1(\\cdot) + 2*N_2(\\cdot)}$$\n",
    "\n",
    "\n",
    "### $$N_r(\\cdot) = \\sum_{w: N(w) = r} 1$$\n",
    "\n",
    "### $$N_r(\\cdot, \\cdot) = \\sum_{v, w: N(v, w) = r} 1$$\n",
    "\n",
    "### $$N_r(v, \\cdot) = \\sum_{w: N(v, w) = r} 1$$\n",
    "\n",
    "### V is the number of words in the vocabulary\n",
    "\n",
    "### $N_r(\\cdot, \\cdot)$ and $N_r(\\cdot)$  are the count-counts for bigrams and unigrams respectively $\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remember to check that probabilities sum up to one:\n",
    "### $$\\sum_w p_{bi}(w|v) = \\sum_w p_{uni}(w) = 1$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y = \"m\"\n",
    "# x = \"'\"\n",
    "\n",
    "# z = train_ngram_lm.get_p_bi(y, x)\n",
    "# z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[('<sos>', '<sos>', 'this'),\n",
       "  ('<sos>', 'this', 'is'),\n",
       "  ('this', 'is', 'a'),\n",
       "  ('is', 'a', 'great'),\n",
       "  ('a', 'great', 'tutu'),\n",
       "  ('great', 'tutu', 'and'),\n",
       "  ('tutu', 'and', 'at'),\n",
       "  ('and', 'at', 'a'),\n",
       "  ('at', 'a', 'really'),\n",
       "  ('a', 'really', 'great'),\n",
       "  ('really', 'great', 'price'),\n",
       "  ('great', 'price', '.'),\n",
       "  ('price', '.', '<eos>'),\n",
       "  ('.', '<eos>', '<eos>')],\n",
       " [('<sos>', '<sos>', 'it'),\n",
       "  ('<sos>', 'it', 'doesn'),\n",
       "  ('it', 'doesn', \"'\"),\n",
       "  ('doesn', \"'\", 't'),\n",
       "  (\"'\", 't', 'look'),\n",
       "  ('t', 'look', 'cheap'),\n",
       "  ('look', 'cheap', 'at'),\n",
       "  ('cheap', 'at', 'all'),\n",
       "  ('at', 'all', '.'),\n",
       "  ('all', '.', '<eos>'),\n",
       "  ('.', '<eos>', '<eos>')],\n",
       " [('<sos>', '<sos>', 'i'),\n",
       "  ('<sos>', 'i', \"'\"),\n",
       "  ('i', \"'\", 'm'),\n",
       "  (\"'\", 'm', 'so'),\n",
       "  ('m', 'so', 'glad'),\n",
       "  ('so', 'glad', 'i'),\n",
       "  ('glad', 'i', 'looked'),\n",
       "  ('i', 'looked', 'on'),\n",
       "  ('looked', 'on', 'amazon'),\n",
       "  ('on', 'amazon', 'and'),\n",
       "  ('amazon', 'and', 'found'),\n",
       "  ('and', 'found', 'such'),\n",
       "  ('found', 'such', 'an'),\n",
       "  ('such', 'an', 'affordable'),\n",
       "  ('an', 'affordable', 'tutu'),\n",
       "  ('affordable', 'tutu', 'that'),\n",
       "  ('tutu', 'that', 'isn'),\n",
       "  ('that', 'isn', \"'\"),\n",
       "  ('isn', \"'\", 't'),\n",
       "  (\"'\", 't', 'made'),\n",
       "  ('t', 'made', 'poorly'),\n",
       "  ('made', 'poorly', '.'),\n",
       "  ('poorly', '.', '<eos>'),\n",
       "  ('.', '<eos>', '<eos>')]]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ngram[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kneser-Ney Smoothing (best to use in practice!) http://smithamilli.com/blog/kneser-ney/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bigram LM\n",
    "###  $$p(s) = \\prod_{i = 1} ^ {N + 1} p(w_i | w_{i-1})$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Likelihood of a Sentence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bigram LM: $$ p(i \\; love \\; this \\; light) = p(i|\\cdot) \\; p(love|i)\\;  p(this|love)\\;  p(light|this) \\\\\n",
    "\\approx \\frac{c(i, \\cdot)}{\\sum_w c(\\cdot, \\; w)} \\; \\frac{c(love, i)}{\\sum_wc(i, \\; w)}\\;  \\frac{c(this, love)}{\\sum_wc(love, \\;w)}\\;  \\frac{c(light, this)}{\\sum_wc(this, \\;w)}$$ \n",
    "\n",
    "### Trigram LM: $$ p(i \\; love \\; this  \\;light) = p(i|\\cdot, \\cdot) \\; p(love|\\cdot, i) \\; p(this|i, love)\\;  p(light|love, this)$$ \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Score Sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['this', 'is', 'a', 'great', 'tutu']]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.0, 5.127565397867753e+77)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n = 3\n",
    "sentence = [['this', 'is', 'a', 'great', 'tutu']]\n",
    "print(sentence)\n",
    "ps = train_ngram_lm.get_prob_sentence(sentence)\n",
    "ss =  train_ngram_lm.get_score_sentence(sentence)\n",
    "ps, ss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['this', 'is', 'a', 'great', 'tutu', 'and', 'at', 'a', 'really', 'great', 'price', '.']]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(4.2919413175965264e-13, 6.675591427844734)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n = 3\n",
    "sentence = [['this', 'is', 'a', 'great', 'tutu', 'and', 'at', 'a', 'really', 'great', 'price', '.']]\n",
    "print(sentence)\n",
    "ps = train_ngram_lm.get_prob_sentence(sentence)\n",
    "ss = train_ngram_lm.get_score_sentence(sentence)\n",
    "ps, ss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentence Generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### No Context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "quality\n",
      "quality wise\n",
      "quality wise they\n",
      "quality wise they are\n",
      "quality wise they are amazingly\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'quality wise they are amazingly'"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_tokens = 5\n",
    "generated_sentence = train_ngram_lm.generate_sentence(num_tokens)\n",
    "generated_sentence\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "second\n",
      "second pair\n",
      "second pair in\n",
      "second pair in rotation\n",
      "second pair in rotation that\n",
      "second pair in rotation that i\n",
      "second pair in rotation that i have\n",
      "second pair in rotation that i have been\n",
      "second pair in rotation that i have been wrangler\n",
      "second pair in rotation that i have been wrangler .\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'second pair in rotation that i have been wrangler .'"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_tokens = 10\n",
    "generated_sentence = train_ngram_lm.generate_sentence(num_tokens, context=('i', 'like', 'the'))\n",
    "generated_sentence\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "when\n",
      "when i\n",
      "when i '\n",
      "when i ' m\n",
      "when i ' m happy\n",
      "when i ' m happy .\n",
      "when i ' m happy . <eos>\n",
      "when i ' m happy . <eos> <eos>\n",
      "when i ' m happy . <eos> <eos> doens\n",
      "when i ' m happy . <eos> <eos> doens coolcon\n",
      "when i ' m happy . <eos> <eos> doens coolcon chucks\n",
      "when i ' m happy . <eos> <eos> doens coolcon chucks yessiree\n",
      "when i ' m happy . <eos> <eos> doens coolcon chucks yessiree bond\n",
      "when i ' m happy . <eos> <eos> doens coolcon chucks yessiree bond loot\n",
      "when i ' m happy . <eos> <eos> doens coolcon chucks yessiree bond loot unattached\n",
      "when i ' m happy . <eos> <eos> doens coolcon chucks yessiree bond loot unattached 6173\n",
      "when i ' m happy . <eos> <eos> doens coolcon chucks yessiree bond loot unattached 6173 centimeter\n",
      "when i ' m happy . <eos> <eos> doens coolcon chucks yessiree bond loot unattached 6173 centimeter advice\n",
      "when i ' m happy . <eos> <eos> doens coolcon chucks yessiree bond loot unattached 6173 centimeter advice retired\n",
      "when i ' m happy . <eos> <eos> doens coolcon chucks yessiree bond loot unattached 6173 centimeter advice retired stripes\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"when i ' m happy . <eos> <eos> doens coolcon chucks yessiree bond loot unattached 6173 centimeter advice retired stripes\""
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_tokens = 20\n",
    "generated_sentence = train_ngram_lm.generate_sentence(num_tokens)\n",
    "generated_sentence\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### With Context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "garden\n",
      "garden and\n",
      "garden and wants\n",
      "garden and wants to\n",
      "garden and wants to see\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'garden and wants to see'"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_tokens = 5\n",
    "generated_sentence = train_ngram_lm.generate_sentence(num_tokens, context=('i', 'like', 'the'))\n",
    "generated_sentence\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "look\n",
      "look of\n",
      "look of the\n",
      "look of the problems\n",
      "look of the problems ,\n",
      "look of the problems , no\n",
      "look of the problems , no complains\n",
      "look of the problems , no complains at\n",
      "look of the problems , no complains at all\n",
      "look of the problems , no complains at all ,\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'look of the problems , no complains at all ,'"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_tokens = 10\n",
    "generated_sentence = train_ngram_lm.generate_sentence(num_tokens, context=('i', 'like', 'the'))\n",
    "generated_sentence\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "elastic\n",
      "elastic is\n",
      "elastic is a\n",
      "elastic is a nice\n",
      "elastic is a nice fit\n",
      "elastic is a nice fit i\n",
      "elastic is a nice fit i appreciate\n",
      "elastic is a nice fit i appreciate being\n",
      "elastic is a nice fit i appreciate being able\n",
      "elastic is a nice fit i appreciate being able to\n",
      "elastic is a nice fit i appreciate being able to wear\n",
      "elastic is a nice fit i appreciate being able to wear it\n",
      "elastic is a nice fit i appreciate being able to wear it with\n",
      "elastic is a nice fit i appreciate being able to wear it with me\n",
      "elastic is a nice fit i appreciate being able to wear it with me .\n",
      "elastic is a nice fit i appreciate being able to wear it with me . <eos>\n",
      "elastic is a nice fit i appreciate being able to wear it with me . <eos> <eos>\n",
      "elastic is a nice fit i appreciate being able to wear it with me . <eos> <eos> cultural\n",
      "elastic is a nice fit i appreciate being able to wear it with me . <eos> <eos> cultural sale\n",
      "elastic is a nice fit i appreciate being able to wear it with me . <eos> <eos> cultural sale dumped\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'elastic is a nice fit i appreciate being able to wear it with me . <eos> <eos> cultural sale dumped'"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_tokens = 20\n",
    "generated_sentence = train_ngram_lm.generate_sentence(num_tokens, context=('i', 'like', 'the'))\n",
    "generated_sentence\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "could\n",
      "could get\n",
      "could get in\n",
      "could get in a\n",
      "could get in a variety\n",
      "could get in a variety of\n",
      "could get in a variety of body\n",
      "could get in a variety of body hair\n",
      "could get in a variety of body hair .\n",
      "could get in a variety of body hair . <eos>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'could get in a variety of body hair . <eos>'"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_tokens = 10\n",
    "generated_sentence = train_ngram_lm.generate_sentence(num_tokens, context=('the', 'worst'))\n",
    "generated_sentence\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "can\n",
      "can '\n",
      "can ' t\n",
      "can ' t that\n",
      "can ' t that easy\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"can ' t that easy\""
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_tokens = 5\n",
    "generated_sentence = train_ngram_lm.generate_sentence(num_tokens, context=('the', 'best'))\n",
    "generated_sentence\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "would\n",
      "would definitely\n",
      "would definitely order\n",
      "would definitely order this\n",
      "would definitely order this model\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'would definitely order this model'"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_tokens = 5\n",
    "generated_sentence = train_ngram_lm.generate_sentence(num_tokens, context=('not', 'what'))\n",
    "generated_sentence\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_tokens = 5\n",
    "generated_sentence = train_ngram_lm.generate_sentence(num_tokens, context=('i', 'will'))\n",
    "generated_sentence\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Log-Likelihood (n-gram)\n",
    "## $$LL = \\sum_{j=1}^{K} \\sum_{i=1}^{T_j + 1} log p_{bi}(w_{j, i} | w_{j, n - i + 1}, \\cdot, w_{j, i - 2}, w_{j, i - 1})$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perplexity\n",
    "## $$PP = exp(-\\frac{LL}{\\sum_j(T_j + 1)})$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "ppl_train = train_ngram_lm.get_perplexity(train_data_tokenized, subsample=10)\n",
    "ppl_valid = train_ngram_lm.get_perplexity(valid_data_tokenized, subsample=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.054956118557522e+16, 785.4807625424293)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ppl_valid, ppl_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interpolation Smoothing - varying N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3285557484179.5693, 1986.5028596317322)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Interpolation Smoothing, N = 2\n",
    "train_ngram_lm_interp2 = NgramLM(train_data_tokenized, all_tokens_train, n=2, smoothing='interpolation')\n",
    "valid_ngram_lm_interp2 = NgramLM(valid_data_tokenized, all_tokens_valid, n=2, smoothing='interpolation')\n",
    "\n",
    "ppl_train_no_interp2 = train_ngram_lm_interp2.get_perplexity(train_data_tokenized, subsample=10)\n",
    "ppl_valid_no_interp2 = train_ngram_lm_interp2.get_perplexity(valid_data_tokenized, subsample=10)\n",
    "\n",
    "ppl_valid_no_interp2, ppl_train_no_interp2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.072384367067956e+16, 968.3797095627817)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Interpolation Smoothing, N = 3\n",
    "train_ngram_lm_interp3 = NgramLM(train_data_tokenized, all_tokens_train, n=3, smoothing='interpolation')\n",
    "valid_ngram_lm_interp3 = NgramLM(valid_data_tokenized, all_tokens_valid, n=3, smoothing='interpolation')\n",
    "\n",
    "ppl_train_no_interp3 = train_ngram_lm_interp3.get_perplexity(train_data_tokenized, subsample=10)\n",
    "ppl_valid_no_interp3 = train_ngram_lm_interp3.get_perplexity(valid_data_tokenized, subsample=10)\n",
    "\n",
    "ppl_valid_no_interp3, ppl_train_no_interp3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2.1015857124167747e+17, 232.46259410383843)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Interpolation Smoothing, N = 5\n",
    "train_ngram_lm_interp5 = NgramLM(train_data_tokenized, all_tokens_train, n=5, smoothing='interpolation')\n",
    "valid_ngram_lm_interp5 = NgramLM(valid_data_tokenized, all_tokens_valid, n=5, smoothing='interpolation')\n",
    "\n",
    "ppl_train_no_interp5 = train_ngram_lm_interp5.get_perplexity(train_data_tokenized, subsample=10)\n",
    "ppl_valid_no_interp5 = train_ngram_lm_interp5.get_perplexity(valid_data_tokenized, subsample=10)\n",
    "\n",
    "ppl_valid_no_interp5, ppl_train_no_interp5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3.1723045337663955e+17, 189.7619965264788)"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Interpolation Smoothing, N = 7\n",
    "train_ngram_lm_interp7 = NgramLM(train_data_tokenized, all_tokens_train, n=7, smoothing='interpolation')\n",
    "valid_ngram_lm_interp7 = NgramLM(valid_data_tokenized, all_tokens_valid, n=7, smoothing='interpolation')\n",
    "\n",
    "ppl_train_no_interp7 = train_ngram_lm_interp7.get_perplexity(train_data_tokenized, subsample=10)\n",
    "ppl_valid_no_interp7 = train_ngram_lm_interp7.get_perplexity(valid_data_tokenized, subsample=10)\n",
    "\n",
    "ppl_valid_no_interp7, ppl_train_no_interp7\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3.547937990377419e+17, 190.88811615400783)"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Interpolation Smoothing, N = 10\n",
    "train_ngram_lm_interp10 = NgramLM(train_data_tokenized, all_tokens_train, n=10, smoothing='interpolation')\n",
    "valid_ngram_lm_interp10 = NgramLM(valid_data_tokenized, all_tokens_valid, n=10, smoothing='interpolation')\n",
    "\n",
    "ppl_train_no_interp10 = train_ngram_lm_interp10.get_perplexity(train_data_tokenized, subsample=10)\n",
    "ppl_valid_no_interp10 = train_ngram_lm_interp10.get_perplexity(valid_data_tokenized, subsample=10)\n",
    "\n",
    "ppl_valid_no_interp10, ppl_train_no_interp10\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's Compare Different Smoothing Techniques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2.08396845152164e+17, 183.51411652373378)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# No Smoothing\n",
    "train_ngram_lm_no_smoothing = NgramLM(train_data_tokenized, all_tokens_train, n=7)\n",
    "valid_ngram_lm_no_smoothing = NgramLM(valid_data_tokenized, all_tokens_valid, n=7)\n",
    "\n",
    "ppl_train_no_smoothing = train_ngram_lm_no_smoothing.get_perplexity(train_data_tokenized, subsample=10)\n",
    "ppl_valid_no_smoothing = train_ngram_lm_no_smoothing.get_perplexity(valid_data_tokenized, subsample=10)\n",
    "\n",
    "ppl_valid_no_smoothing, ppl_train_no_smoothing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16345.815746103941, 7488.503410213912)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Additive Smoothing\n",
    "train_ngram_lm_additive = NgramLM(train_data_tokenized, all_tokens_train, n=7, smoothing='additive', delta=0.5)\n",
    "valid_ngram_lm_additive = NgramLM(valid_data_tokenized, all_tokens_valid, n=7, smoothing='additive', delta=0.5)\n",
    "\n",
    "ppl_train_no_additive = train_ngram_lm_additive.get_perplexity(train_data_tokenized, subsample=10)\n",
    "ppl_valid_no_additive = train_ngram_lm_additive.get_perplexity(valid_data_tokenized, subsample=10)\n",
    "\n",
    "ppl_valid_no_additive, ppl_train_no_additive\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12880.12202604883, 3658.278365175098)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Additive Smoothing\n",
    "train_ngram_lm_additive_d2 = NgramLM(train_data_tokenized, all_tokens_train, n=7, smoothing='additive', delta=0.2)\n",
    "valid_ngram_lm_additive_d2 = NgramLM(valid_data_tokenized, all_tokens_valid, n=7, smoothing='additive', delta=0.2)\n",
    "\n",
    "ppl_train_no_additive_d2 = train_ngram_lm_additive_d2.get_perplexity(train_data_tokenized, subsample=10)\n",
    "ppl_valid_no_additive_d2 = train_ngram_lm_additive_d2.get_perplexity(valid_data_tokenized, subsample=10)\n",
    "\n",
    "ppl_valid_no_additive_d2, ppl_train_no_additive_d2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18473.27980811132, 10361.633766989804)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Additive Smoothing\n",
    "train_ngram_lm_additive_d8 = NgramLM(train_data_tokenized, all_tokens_train, n=7, smoothing='additive', delta=0.8)\n",
    "valid_ngram_lm_additive_d8 = NgramLM(valid_data_tokenized, all_tokens_valid, n=7, smoothing='additive', delta=0.8)\n",
    "\n",
    "ppl_train_no_additive_d8 = train_ngram_lm_additive_d8.get_perplexity(train_data_tokenized, subsample=10)\n",
    "ppl_valid_no_additive_d8 = train_ngram_lm_additive_d8.get_perplexity(valid_data_tokenized, subsample=10)\n",
    "\n",
    "ppl_valid_no_additive_d8, ppl_train_no_additive_d8\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19571.330911807145, 11941.112187375262)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Additive Smoothing\n",
    "train_ngram_lm_add1 = NgramLM(train_data_tokenized, all_tokens_train, n=7, smoothing='add-one')\n",
    "valid_ngram_lm_add1 = NgramLM(valid_data_tokenized, all_tokens_valid, n=7, smoothing='add-one')\n",
    "\n",
    "ppl_train_no_add1 = train_ngram_lm_add1.get_perplexity(train_data_tokenized, subsample=10)\n",
    "ppl_valid_no_add1 = train_ngram_lm_add1.get_perplexity(valid_data_tokenized, subsample=10)\n",
    "\n",
    "ppl_valid_no_add1, ppl_train_no_add1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2.2144202796120246e+17, 1009.9081710652557)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Interpolation Smoothing\n",
    "train_ngram_lm_interp_a2 = NgramLM(train_data_tokenized, all_tokens_train, n=7, smoothing='interpolation', alpha=0.2)\n",
    "valid_ngram_lm_interp_a2 = NgramLM(valid_data_tokenized, all_tokens_valid, n=7, smoothing='interpolation', alpha=0.2)\n",
    "\n",
    "ppl_train_no_interp_a2 = train_ngram_lm_interp_a2.get_perplexity(train_data_tokenized, subsample=10)\n",
    "ppl_valid_no_interp_a2 = train_ngram_lm_interp_a2.get_perplexity(valid_data_tokenized, subsample=10)\n",
    "\n",
    "ppl_valid_no_interp_a2, ppl_train_no_interp_a2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2.1015857124167747e+17, 232.46259410383843)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Interpolation Smoothing\n",
    "train_ngram_lm_interp_a8 = NgramLM(train_data_tokenized, all_tokens_train, n=7, smoothing='interpolation', alpha=0.8)\n",
    "valid_ngram_lm_interp_a8 = NgramLM(valid_data_tokenized, all_tokens_valid, n=7, smoothing='interpolation', alpha=0.8)\n",
    "\n",
    "ppl_train_no_interp_a8 = train_ngram_lm_interp_a8.get_perplexity(train_data_tokenized, subsample=10)\n",
    "ppl_valid_no_interp_a8 = train_ngram_lm_interp_a8.get_perplexity(valid_data_tokenized, subsample=10)\n",
    "\n",
    "ppl_valid_no_interp_a8, ppl_train_no_interp_a8\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2.1391813885036947e+17, 382.5021497636743)"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Interpolation Smoothing\n",
    "train_ngram_lm_interp_a5 = NgramLM(train_data_tokenized, all_tokens_train, n=7, smoothing='interpolation', alpha=0.5)\n",
    "valid_ngram_lm_interp_a5 = NgramLM(valid_data_tokenized, all_tokens_valid, n=7, smoothing='interpolation', alpha=0.5)\n",
    "\n",
    "ppl_train_no_interp_a5 = train_ngram_lm_interp_a5.get_perplexity(train_data_tokenized, subsample=10)\n",
    "ppl_valid_no_interp_a5 = train_ngram_lm_interp_a5.get_perplexity(valid_data_tokenized, subsample=10)\n",
    "\n",
    "ppl_valid_no_interp_a5, ppl_train_no_interp_a5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Discounted Interpolation Smoothing\n",
    "# train_ngram_lm_discount = NgramLM(train_data_tokenized, all_tokens_train, n=3, smoothing='discounting')\n",
    "# valid_ngram_lm_discount = NgramLM(valid_data_tokenized, all_tokens_valid, n=3, smoothing='discounting')\n",
    "\n",
    "# ppl_train_no_discount = train_ngram_lm_discount.get_perplexity(train_data_tokenized)\n",
    "# ppl_valid_no_discount = train_ngram_lm_discount.get_perplexity(valid_data_tokenized)\n",
    "\n",
    "# ppl_valid_no_discount, ppl_train_no_discount\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Additive Smoothing - varying N"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sentence Probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['this', 'is', 'a', 'great', 'tutu']]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.0, 5.127565397867753e+77)"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence = [['this', 'is', 'a', 'great', 'tutu']]\n",
    "print(sentence)\n",
    "ps = train_ngram_lm.get_prob_sentence(sentence)\n",
    "ss = train_ngram_lm.get_score_sentence(sentence)\n",
    "ps, ss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['this', 'is', 'a', 'great', 'tutu', 'and', 'at', 'a', 'really', 'great', 'price', '.']]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1.887615753771853e-14, 8.221273452877178)"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence = [['this', 'is', 'a', 'great', 'tutu', 'and', 'at', 'a', 'really', 'great', 'price', '.']]\n",
    "print(sentence)\n",
    "ps = train_ngram_lm_interp3.get_prob_sentence(sentence)\n",
    "ss = train_ngram_lm_interp3.get_score_sentence(sentence)\n",
    "ps, ss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['this', 'is', 'a', 'great', 'tutu', 'and', 'at', 'a', 'really', 'great', 'price', '.']]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(2.0890490981023452e-07, 2.4714065720144007)"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence = [['this', 'is', 'a', 'great', 'tutu', 'and', 'at', 'a', 'really', 'great', 'price', '.']]\n",
    "print(sentence)\n",
    "ps = train_ngram_lm_interp5.get_prob_sentence(sentence)\n",
    "ss = train_ngram_lm_interp5.get_score_sentence(sentence)\n",
    "ps, ss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['this', 'is', 'a', 'great', 'tutu', 'and', 'at', 'a', 'really', 'great', 'price', '.']]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1.7987031324049532e-07, 2.264655425293293)"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence = [['this', 'is', 'a', 'great', 'tutu', 'and', 'at', 'a', 'really', 'great', 'price', '.']]\n",
    "print(sentence)\n",
    "ps = train_ngram_lm_interp7.get_prob_sentence(sentence)\n",
    "ss = train_ngram_lm_interp7.get_score_sentence(sentence)\n",
    "ps, ss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['this', 'is', 'a', 'great', 'tutu']]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.0, 9.063042790366942e+184)"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence = [['this', 'is', 'a', 'great', 'tutu']]\n",
    "print(sentence)\n",
    "ps = train_ngram_lm_interp10.get_prob_sentence(sentence)\n",
    "ss = train_ngram_lm_interp10.get_score_sentence(sentence)\n",
    "ps, ss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['this', 'is', 'a', 'great', 'tutu', 'and', 'at', 'a', 'really', 'great', 'price', '.']]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(9.246774960655664e-44, 339.94787908610914)"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence = [['this', 'is', 'a', 'great', 'tutu', 'and', 'at', 'a', 'really', 'great', 'price', '.']]\n",
    "print(sentence)\n",
    "ps = train_ngram_lm_additive.get_prob_sentence(sentence)\n",
    "ss = train_ngram_lm_additive.get_score_sentence(sentence)\n",
    "ps, ss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['i', 'like', 'pandas']]\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'train_ngram_lm_additive' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-257ff62052a2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0msentence\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'i'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'like'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'pandas'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_ngram_lm_additive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_prob_sentence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_ngram_lm_additive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_score_sentence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train_ngram_lm_additive' is not defined"
     ]
    }
   ],
   "source": [
    "sentence = [['i', 'like', 'pandas']]\n",
    "print(sentence)\n",
    "ps = train_ngram_lm_additive.get_prob_sentence(sentence)\n",
    "ss = train_ngram_lm_additive.get_score_sentence(sentence)\n",
    "ps, ss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = [['i really like this watch']]\n",
    "print(sentence)\n",
    "ps = train_ngram_lm_additive.get_prob_sentence(sentence)\n",
    "ss = train_ngram_lm_additive.get_score_sentence(sentence)\n",
    "ps, ss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = [['my wife really likes the color of this dress']]\n",
    "print(sentence)\n",
    "ps = train_ngram_lm_additive.get_prob_sentence(sentence)\n",
    "ss = train_ngram_lm_additive.get_score_sentence(sentence)\n",
    "ps, ss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sentence Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "big\n",
      "big student\n",
      "big student backpack\n",
      "big student backpack and\n",
      "big student backpack and eats\n",
      "big student backpack and eats one\n",
      "big student backpack and eats one of\n",
      "big student backpack and eats one of the\n",
      "big student backpack and eats one of the material\n",
      "big student backpack and eats one of the material didn\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'big student backpack and eats one of the material didn'"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_tokens = 10\n",
    "generated_sentence = train_ngram_lm_interp3.generate_sentence(num_tokens)\n",
    "generated_sentence\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inside\n",
      "inside ,\n",
      "inside , i\n",
      "inside , i use\n",
      "inside , i use the\n",
      "inside , i use the amazon\n",
      "inside , i use the amazon visa\n",
      "inside , i use the amazon visa card\n",
      "inside , i use the amazon visa card and\n",
      "inside , i use the amazon visa card and there\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'inside , i use the amazon visa card and there'"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_tokens = 10\n",
    "generated_sentence = train_ngram_lm_interp5.generate_sentence(num_tokens)\n",
    "generated_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "they\n",
      "they are\n",
      "they are blindingly\n",
      "they are blindingly white\n",
      "they are blindingly white makes\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'they are blindingly white makes'"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_tokens = 10\n",
    "generated_sentence = train_ngram_lm_interp7.generate_sentence(num_tokens)\n",
    "generated_sentence\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "this\n",
      "this ring\n",
      "this ring was\n",
      "this ring was on\n",
      "this ring was on my\n",
      "this ring was on my wife\n",
      "this ring was on my wife '\n",
      "this ring was on my wife ' s\n",
      "this ring was on my wife ' s wish\n",
      "this ring was on my wife ' s wish list\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"this ring was on my wife ' s wish list\""
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_tokens = 10\n",
    "generated_sentence = train_ngram_lm_interp10.generate_sentence(num_tokens)\n",
    "generated_sentence\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the\n",
      "the best\n",
      "the best foot\n",
      "the best foot support\n",
      "the best foot support system\n",
      "the best foot support system ,\n",
      "the best foot support system , and\n",
      "the best foot support system , and no\n",
      "the best foot support system , and no tight\n",
      "the best foot support system , and no tight toe\n",
      "the best foot support system , and no tight toe bed\n",
      "the best foot support system , and no tight toe bed .\n",
      "the best foot support system , and no tight toe bed . <eos>\n",
      "the best foot support system , and no tight toe bed . <eos> <eos>\n",
      "the best foot support system , and no tight toe bed . <eos> <eos> <eos>\n",
      "the best foot support system , and no tight toe bed . <eos> <eos> <eos> <eos>\n",
      "the best foot support system , and no tight toe bed . <eos> <eos> <eos> <eos> <eos>\n",
      "the best foot support system , and no tight toe bed . <eos> <eos> <eos> <eos> <eos> <eos>\n",
      "the best foot support system , and no tight toe bed . <eos> <eos> <eos> <eos> <eos> <eos> <eos>\n",
      "the best foot support system , and no tight toe bed . <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'the best foot support system , and no tight toe bed . <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos>'"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_tokens = 20\n",
    "generated_sentence = train_ngram_lm_interp10.generate_sentence(num_tokens)\n",
    "generated_sentence\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "or\n",
      "or at\n",
      "or at least\n",
      "or at least nobody\n",
      "or at least nobody '\n",
      "or at least nobody ' s\n",
      "or at least nobody ' s said\n",
      "or at least nobody ' s said anything\n",
      "or at least nobody ' s said anything yet\n",
      "or at least nobody ' s said anything yet .\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"or at least nobody ' s said anything yet .\""
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_tokens = 10\n",
    "generated_sentence = train_ngram_lm_additive.generate_sentence(num_tokens)\n",
    "generated_sentence\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i\n",
      "i will\n",
      "i will recommend\n",
      "i will recommend this\n",
      "i will recommend this to\n",
      "i will recommend this to my\n",
      "i will recommend this to my friends\n",
      "i will recommend this to my friends !\n",
      "i will recommend this to my friends ! <eos>\n",
      "i will recommend this to my friends ! <eos> <eos>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'i will recommend this to my friends ! <eos> <eos>'"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_tokens = 10\n",
    "generated_sentence = train_ngram_lm_no_smoothing.generate_sentence(num_tokens)\n",
    "generated_sentence\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "include_colab_link": true,
   "name": "ngram-lm.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
