{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ngram-lm.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "eda026482299482fb1d5b17ba9a04947": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_ef352532e4e34c8caba675cc5e5982f7",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_b3e989f2500f4700a106e7a2609b13bd",
              "IPY_MODEL_cd55a0eb6b394087a2563609f4cad0a4"
            ]
          }
        },
        "ef352532e4e34c8caba675cc5e5982f7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "b3e989f2500f4700a106e7a2609b13bd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_112c68da84dd481994ee7e0b81bc7ae6",
            "_dom_classes": [],
            "description": "",
            "_model_name": "IntProgressModel",
            "bar_style": "success",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_3d6fb20385d142668806694bfdeb2899"
          }
        },
        "cd55a0eb6b394087a2563609f4cad0a4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_497c840137b3425bada97d393dac0493",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 107790/? [00:05&lt;00:00, 21121.77it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_33a90265684d40ca868aebedfe61b34e"
          }
        },
        "112c68da84dd481994ee7e0b81bc7ae6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "3d6fb20385d142668806694bfdeb2899": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "497c840137b3425bada97d393dac0493": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "33a90265684d40ca868aebedfe61b34e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "35c064a006304de7bb0905440fa48891": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_829547d2c87941d79ea7b9998d0b63e1",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_c753a68d06ee49fa9c4eb5e9bec46c4c",
              "IPY_MODEL_0eca927aadf243e287f5c06e02135c02"
            ]
          }
        },
        "829547d2c87941d79ea7b9998d0b63e1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "c753a68d06ee49fa9c4eb5e9bec46c4c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_1fb179ab86c04fa1b77f02d392c052de",
            "_dom_classes": [],
            "description": "",
            "_model_name": "IntProgressModel",
            "bar_style": "success",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_c783d753d2844853843d6439fcf81053"
          }
        },
        "0eca927aadf243e287f5c06e02135c02": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_945310b0198640a3aea3f376f1a872cc",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 15172/? [00:00&lt;00:00, 19671.43it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_5d671d01ec894516bbf81bb8ef0fd389"
          }
        },
        "1fb179ab86c04fa1b77f02d392c052de": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "c783d753d2844853843d6439fcf81053": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "945310b0198640a3aea3f376f1a872cc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "5d671d01ec894516bbf81bb8ef0fd389": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Kabongosalomon/AMMI-NLP/blob/master/Part%2002/001_LM/2019/ngram_lm.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y-or1wezVBMu",
        "colab_type": "text"
      },
      "source": [
        "# Language Modeling\n",
        "\n",
        "### Goal: compute a probabilty distribution over all possible sentences:\n",
        "\n",
        "\n",
        "### $$p(W) = p(w_1, w_2, ..., w_T)$$\n",
        "\n",
        "### This unsupervised learning problem can be framed as a sequence of supervised learning problems:\n",
        "\n",
        "### $$p(W) = p(w_1) * p(w_2|w_1) * ... * p(w_T|w_1, ..., w_{T-1})$$\n",
        "\n",
        "### If we have K sentences, where the j-th sentence has T_j words for all j frmo 1 to K, then we want to max:\n",
        "\n",
        "### $$log p(W) = \\sum_{j = 1}^K \\sum_{i=1}^{T_j} log p(w_i | w_{<i})$$\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KbveLoNlVBMx",
        "colab_type": "text"
      },
      "source": [
        "# N-gram language model\n",
        "\n",
        "### Goal: estimate the n-gram probabilities using counts of sequences of n consecutive words\n",
        "\n",
        "### Given a sequence of words $w$, we want to compute\n",
        "\n",
        "###  $$P(w_i|w_{i−1}, w_{i−2}, …, w_{i−n+1})$$\n",
        "\n",
        "### Where $w_i$ is the i-th word of the sequence.\n",
        "\n",
        "### $$P(w_i|w_{i−n+1}, ..., w_{i−2}, w_{i−1}) = \\frac{p(w_{i−n+1}, ..., w_{i−2}, w_{i−1}, w_i)}{\\sum_{w \\in V} p(w_{i−n+1}, ..., w_{i−2}, w_{i−1}, w)}$$\n",
        "\n",
        "### Key Idea: We can estimate the probabilities using counts of n-grams in our dataset \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hcdzrxLpVBMz",
        "colab_type": "text"
      },
      "source": [
        "## N-gram Probabilities"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7egmH__HVBM1",
        "colab_type": "text"
      },
      "source": [
        "## $$P(w_i|w_{i−n+1}, ..., w_{i−2}, w_{i−1}) \\approx \\frac{c(w_{i−n+1}, ..., w_{i−2}, w_{i−1}, w_i)}{\\sum_{w \\in V} c(w_{i−n+1}, ..., w_{i−2}, w_{i−1}, w)}$$\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c6KV9TGIVBM3",
        "colab_type": "text"
      },
      "source": [
        "## Bigram Probabilities\n",
        "\n",
        "## $$p(w_i | w_{i-1}) = \\frac{c(w_{i-1}, w_i)}{\\sum_{w_i} c(w_{i-1}, w_i)} $$\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VKizkCdOVBM4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 435
        },
        "outputId": "389b6480-bde7-4fbc-f6a0-08950c8c0446"
      },
      "source": [
        "!python -m spacy download en_core_web_sm"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: en_core_web_sm==2.2.5 from https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.2.5/en_core_web_sm-2.2.5.tar.gz#egg=en_core_web_sm==2.2.5 in /usr/local/lib/python3.6/dist-packages (2.2.5)\n",
            "Requirement already satisfied: spacy>=2.2.2 in /usr/local/lib/python3.6/dist-packages (from en_core_web_sm==2.2.5) (2.2.4)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (0.6.0)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.18.2)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (4.38.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (46.0.0)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (0.4.1)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.2)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.0)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.2)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (2.0.3)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (7.4.0)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (3.0.2)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (2.21.0)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.1.3)\n",
            "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_sm==2.2.5) (1.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (2019.11.28)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (2.8)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (1.24.3)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.0.4)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.1.0)\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the model via spacy.load('en_core_web_sm')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IhggMYFHVBM_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "outputId": "87eea497-6fe7-41b1-c853-afc467c7433a"
      },
      "source": [
        "!pip install altair\n",
        "!pip install pygtrie"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: altair in /usr/local/lib/python3.6/dist-packages (4.0.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from altair) (1.18.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (from altair) (0.25.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.6/dist-packages (from altair) (2.11.1)\n",
            "Requirement already satisfied: jsonschema in /usr/local/lib/python3.6/dist-packages (from altair) (2.6.0)\n",
            "Requirement already satisfied: entrypoints in /usr/local/lib/python3.6/dist-packages (from altair) (0.3)\n",
            "Requirement already satisfied: toolz in /usr/local/lib/python3.6/dist-packages (from altair) (0.10.0)\n",
            "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.6/dist-packages (from pandas->altair) (2.8.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas->altair) (2018.9)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.6/dist-packages (from jinja2->altair) (1.1.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2.6.1->pandas->altair) (1.12.0)\n",
            "Collecting pygtrie\n",
            "  Downloading https://files.pythonhosted.org/packages/18/41/2e5cefc895a32d9ca0f3574bd0df09e53a697023579a93582bedc4eeac4d/pygtrie-2.3.2.tar.gz\n",
            "Building wheels for collected packages: pygtrie\n",
            "  Building wheel for pygtrie (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pygtrie: filename=pygtrie-2.3.2-cp36-none-any.whl size=18867 sha256=21248ee993b92c4a069f6e1ebf7b0cd9ef7fba36717c1e5454a0fba52db48504\n",
            "  Stored in directory: /root/.cache/pip/wheels/1c/10/3c/2d28c8ac56cda265d0c16ca129f50e5c3526f49a7fbe224cd9\n",
            "Successfully built pygtrie\n",
            "Installing collected packages: pygtrie\n",
            "Successfully installed pygtrie-2.3.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3gNqQoORVBNH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "e3821fd1-9cca-4d17-eba0-04b56d5aacbd"
      },
      "source": [
        "!git clone https://github.com/Kabongosalomon/AMMI-NLP.git\n",
        "%cd AMMI-NLP/Part\\ 02/001_LM/2019"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fatal: destination path 'AMMI-NLP' already exists and is not an empty directory.\n",
            "/content/AMMI-NLP/Part 02/001_LM/2019\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zoSPQd4uVBNM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import sys\n",
        "sys.path.append('c_utils/')\n",
        "from c_utils import ngram_utils as ngram_utils\n",
        "import c_utils.global_variables as gl\n",
        "import torch\n",
        "import random\n",
        "from c_utils.ngram_utils import NgramLM"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "H20pktPiA63a",
        "outputId": "b87ab16f-ab52-428e-b7c9-575f4c7ef3b8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "torch.manual_seed(1)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7fbebd72fad0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PSgQ0mY2VBNY",
        "colab_type": "text"
      },
      "source": [
        "### Load Data from .txt Files"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IH1lrtgKVBNZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Read data from .txt files and create lists of reviews\n",
        "\n",
        "train_data = []\n",
        "# create a list of all the reviews \n",
        "with open('../../data/amazon_train.txt', 'r') as f: # need to edit this depending of your folder structure \n",
        "    train_data = [review for review in f.read().split('\\n') if review]\n",
        "    \n",
        "valid_data = []\n",
        "# create a list of all the reviews \n",
        "with open('../../data/amazon_valid.txt', 'r') as f:\n",
        "    valid_data = [review for review in f.read().split('\\n') if review]\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BIpuEdLKVBNe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# type(train_data), len(train_data), \\\n",
        "# type(train_data[0]), len(train_data[0]), \\\n",
        "# type(train_data[0][0]), len(train_data[0][0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eFOIk3I5VBNi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        },
        "outputId": "339b8fdb-b0fd-4c2c-9ae7-f78c17675b3a"
      },
      "source": [
        "train_data[0], train_data[0][0], len(train_data)\n"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(\"this is a great tutu and at a really great price . it doesn ' t look cheap at all . i ' m so glad i looked on amazon and found such an affordable tutu that isn ' t made poorly . a + + \",\n",
              " 't',\n",
              " 22288)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sGQpjkS9VBNn",
        "colab_type": "text"
      },
      "source": [
        "### Process the Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z1p55-5eVBNp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 115,
          "referenced_widgets": [
            "eda026482299482fb1d5b17ba9a04947",
            "ef352532e4e34c8caba675cc5e5982f7",
            "b3e989f2500f4700a106e7a2609b13bd",
            "cd55a0eb6b394087a2563609f4cad0a4",
            "112c68da84dd481994ee7e0b81bc7ae6",
            "3d6fb20385d142668806694bfdeb2899",
            "497c840137b3425bada97d393dac0493",
            "33a90265684d40ca868aebedfe61b34e",
            "35c064a006304de7bb0905440fa48891",
            "829547d2c87941d79ea7b9998d0b63e1",
            "c753a68d06ee49fa9c4eb5e9bec46c4c",
            "0eca927aadf243e287f5c06e02135c02",
            "1fb179ab86c04fa1b77f02d392c052de",
            "c783d753d2844853843d6439fcf81053",
            "945310b0198640a3aea3f376f1a872cc",
            "5d671d01ec894516bbf81bb8ef0fd389"
          ]
        },
        "outputId": "35dfc0c2-36d2-4ffe-f041-74e631d45950"
      },
      "source": [
        "# Tokenize the Datasets\n",
        "# TODO: this takes a really long time !! why?\n",
        "train_data_tokenized, all_tokens_train = ngram_utils.tokenize_dataset(train_data)\n",
        "valid_data_tokenized, all_tokens_valid = ngram_utils.tokenize_dataset(valid_data)\n"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "eda026482299482fb1d5b17ba9a04947",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "35c064a006304de7bb0905440fa48891",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4GS4e6oWVBNu",
        "colab_type": "text"
      },
      "source": [
        "Let's look at the tokenized data!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GKV3iYP8VBNw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 242
        },
        "outputId": "a3f2ead4-9e2b-4187-ae8e-c0467d7877b9"
      },
      "source": [
        "# # Number of All Tokens\n",
        "# len(all_tokens_train), all_tokens_train[0], \\\n",
        "len(train_data_tokenized), train_data_tokenized[0]"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(107790,\n",
              " ['this',\n",
              "  'is',\n",
              "  'a',\n",
              "  'great',\n",
              "  'tutu',\n",
              "  'and',\n",
              "  'at',\n",
              "  'a',\n",
              "  'really',\n",
              "  'great',\n",
              "  'price',\n",
              "  '.'])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7_2VNndOVBN1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_ngram_lm = NgramLM(train_data_tokenized, all_tokens_train, n=3, smoothing=None)\n",
        "valid_ngram_lm = NgramLM(valid_data_tokenized, all_tokens_valid, n=3, smoothing=None)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NoAG9HU6VBN6",
        "colab_type": "code",
        "colab": {},
        "outputId": "0bce5438-bbad-4178-e5e9-3b151379464f"
      },
      "source": [
        "train_ngram_lm.trie_ngram['./<eos>/<eos>']"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "96175"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h5DsvaYNVBOA",
        "colab_type": "code",
        "colab": {},
        "outputId": "9c6dba55-2d01-4841-92d1-c16088a2e817"
      },
      "source": [
        "train_ngram_lm.n, train_ngram_lm.frac_vocab"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3, 0.9)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U67ZMtjkVBOG",
        "colab_type": "code",
        "colab": {},
        "outputId": "d86f1b4e-a3cb-4bbd-92ef-126f968338bb"
      },
      "source": [
        "valid_ngram_lm.id2token[0:10]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['<unk>', '<sos>', '<eos>', '.', 'the', 'i', ',', 'and', 'a', 'it']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qrWu9J2MVBOK",
        "colab_type": "code",
        "colab": {},
        "outputId": "ab43844a-2215-442d-9730-dbb286f1d687"
      },
      "source": [
        "valid_ngram_lm.token2id['<unk>'], valid_ngram_lm.token2id['<sos>'], valid_ngram_lm.token2id['the']"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0, 1, 4)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hP3uv3VxVBOP",
        "colab_type": "code",
        "colab": {},
        "outputId": "18f578f3-787d-4e22-a046-37b9f664d2ce"
      },
      "source": [
        "valid_ngram_lm.vocab_ngram[:10], valid_ngram_lm.count_ngram[:10]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((('.', '<eos>', '<eos>'),\n",
              "  ('<sos>', '<sos>', 'i'),\n",
              "  ('<sos>', '<sos>', 'the'),\n",
              "  ('<sos>', '<sos>', 'it'),\n",
              "  ('!', '<eos>', '<eos>'),\n",
              "  ('<sos>', '<sos>', 'this'),\n",
              "  ('it', \"'\", 's'),\n",
              "  ('.', '.', '.'),\n",
              "  ('.', '.', '<eos>'),\n",
              "  ('<sos>', '<sos>', 'they')),\n",
              " (13625, 3635, 1425, 1100, 1049, 762, 687, 655, 580, 569))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6-6SZEbGVBOT",
        "colab_type": "code",
        "colab": {},
        "outputId": "9cdca250-eb5f-40e7-f24c-1496fdf5f63b"
      },
      "source": [
        "valid_ngram_lm.vocab_bigram[:10], valid_ngram_lm.count_bigram[:10]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((('.', '<eos>'),\n",
              "  ('<sos>', 'i'),\n",
              "  ('<sos>', 'the'),\n",
              "  (\"'\", 't'),\n",
              "  (\"'\", 's'),\n",
              "  ('.', '.'),\n",
              "  ('<sos>', 'it'),\n",
              "  ('!', '<eos>'),\n",
              "  (',', 'and'),\n",
              "  (',', 'but')),\n",
              " (13625, 3635, 1425, 1261, 1249, 1238, 1100, 1049, 900, 838))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xPRGjbyXVBOX",
        "colab_type": "code",
        "colab": {},
        "outputId": "283fc4d9-1f26-4ea9-80e9-c492ede4c092"
      },
      "source": [
        "valid_ngram_lm.vocab_unigram[:10], valid_ngram_lm.count_unigram[:10]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((('.',),\n",
              "  ('the',),\n",
              "  ('i',),\n",
              "  (',',),\n",
              "  ('and',),\n",
              "  ('a',),\n",
              "  ('it',),\n",
              "  ('to',),\n",
              "  (\"'\",),\n",
              "  ('is',)),\n",
              " (14883, 9408, 8000, 7525, 6226, 5774, 5085, 4550, 3816, 3695))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "igzXhVLjVBOd",
        "colab_type": "code",
        "colab": {},
        "outputId": "71434a37-547f-4c38-c588-f8f285452777"
      },
      "source": [
        "valid_ngram_lm.vocab_prev_ngram[:10], valid_ngram_lm.count_prev_ngram[:10]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((('.', '<eos>'),\n",
              "  ('<sos>', 'i'),\n",
              "  ('<sos>', 'the'),\n",
              "  (\"'\", 't'),\n",
              "  (\"'\", 's'),\n",
              "  ('.', '.'),\n",
              "  ('<sos>', 'it'),\n",
              "  ('!', '<eos>'),\n",
              "  (',', 'and'),\n",
              "  (',', 'but')),\n",
              " (13625, 3635, 1425, 1261, 1249, 1238, 1100, 1049, 900, 838))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fjpnFpCnVBOh",
        "colab_type": "code",
        "colab": {},
        "outputId": "cb589da6-ebc4-480a-bb63-ce4cbc8b41e7"
      },
      "source": [
        "valid_ngram_lm.id2token_ngram[:10]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('.', '<eos>', '<eos>'),\n",
              " ('<sos>', '<sos>', 'i'),\n",
              " ('<sos>', '<sos>', 'the'),\n",
              " ('<sos>', '<sos>', 'it'),\n",
              " ('!', '<eos>', '<eos>'),\n",
              " ('<sos>', '<sos>', 'this'),\n",
              " ('it', \"'\", 's'),\n",
              " ('.', '.', '.'),\n",
              " ('.', '.', '<eos>'),\n",
              " ('<sos>', '<sos>', 'they')]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yPhnY2E5VBOl",
        "colab_type": "code",
        "colab": {},
        "outputId": "c7c07651-a57b-49e2-a379-876c5b4b6c30"
      },
      "source": [
        "valid_ngram_lm.token2id_ngram[('.', '<eos>', '<eos>')], valid_ngram_lm.token2id_ngram[('.', '.', '<eos>')]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0, 8)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5oDqL9LFVBOp",
        "colab_type": "text"
      },
      "source": [
        "#### Build the Vocabulary \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BIoRX7fzVBOq",
        "colab_type": "code",
        "colab": {},
        "outputId": "3706401e-f728-4539-cbf4-5ccc6ab5a57c"
      },
      "source": [
        "# Build a vocabulary using all the tokens found in train data (90% of most common ones)\n",
        "print('Word vocabulary size: {} words'.format(len(train_ngram_lm.token2id)))        "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Word vocabulary size: 20806 words\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ll6fR58CVBOx",
        "colab_type": "text"
      },
      "source": [
        "### CORPUS ANALYSIS (Train + Valid Data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QqcqbQ6aVBOz",
        "colab_type": "text"
      },
      "source": [
        "#### Number of Tokens in the Corpus Data\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fbeslB5FVBO0",
        "colab_type": "code",
        "colab": {},
        "outputId": "5c47ad4b-0bc7-4356-9dc4-db28683340cb"
      },
      "source": [
        "print(\"Number of All Tokens \", len(all_tokens_train))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of All Tokens  1623446\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7-S_MjWiVBO5",
        "colab_type": "text"
      },
      "source": [
        "#### Number of Sentences in the Train Data\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Fb_qaiIVBO6",
        "colab_type": "code",
        "colab": {},
        "outputId": "9aa1e0b7-b292-4abf-af96-3652cc8a0e86"
      },
      "source": [
        "print(\"Number of Sentences \", len(train_ngram_lm.raw_data))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of Sentences  107790\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Oq9XzfFVBO-",
        "colab_type": "text"
      },
      "source": [
        "## N-grams"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B2Kk8EbLVBPA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "n = 3 # trigrams"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xnb78I1HVBPE",
        "colab_type": "text"
      },
      "source": [
        "### Function for padding the sentences with special markers sentence beginning and end, i.e. $<bos>$ and $<eos>$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UXcC1cuTVBPG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_padded = train_ngram_lm.padded_data\n",
        "train_ngram = train_ngram_lm.ngram_data\n",
        "vocab_ngram = train_ngram_lm.vocab_ngram\n",
        "count_ngram = train_ngram_lm.count_ngram "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0bTjlvFBVBPK",
        "colab_type": "code",
        "colab": {},
        "outputId": "0cfb6478-a9b8-430b-a078-15c0819f7c7e"
      },
      "source": [
        "train_padded[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['<sos>',\n",
              " '<sos>',\n",
              " 'this',\n",
              " 'is',\n",
              " 'a',\n",
              " 'great',\n",
              " 'tutu',\n",
              " 'and',\n",
              " 'at',\n",
              " 'a',\n",
              " 'really',\n",
              " 'great',\n",
              " 'price',\n",
              " '.',\n",
              " '<eos>',\n",
              " '<eos>']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "76RS3VhxVBPO",
        "colab_type": "text"
      },
      "source": [
        "### Function for finding all N-grams"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f8cw3x_XVBPQ",
        "colab_type": "code",
        "colab": {},
        "outputId": "138c3fdf-980f-4bf8-e5f2-bc5a13801d3d"
      },
      "source": [
        "train_ngram[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('<sos>', '<sos>', 'this'),\n",
              " ('<sos>', 'this', 'is'),\n",
              " ('this', 'is', 'a'),\n",
              " ('is', 'a', 'great'),\n",
              " ('a', 'great', 'tutu'),\n",
              " ('great', 'tutu', 'and'),\n",
              " ('tutu', 'and', 'at'),\n",
              " ('and', 'at', 'a'),\n",
              " ('at', 'a', 'really'),\n",
              " ('a', 'really', 'great'),\n",
              " ('really', 'great', 'price'),\n",
              " ('great', 'price', '.'),\n",
              " ('price', '.', '<eos>'),\n",
              " ('.', '<eos>', '<eos>')]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pBySUtVjVBPU",
        "colab_type": "code",
        "colab": {},
        "outputId": "59b62726-38df-44d0-9e0a-4eada5b3669d"
      },
      "source": [
        "vocab_ngram[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('.', '<eos>', '<eos>')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UgtXlmRaVBPY",
        "colab_type": "code",
        "colab": {},
        "outputId": "10836b0c-f29c-4c23-d800-0e6ea2560bdd"
      },
      "source": [
        "count_ngram[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "96175"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z3MGbGKvVBPc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "trie_ngram = train_ngram_lm.trie_ngram\n",
        "# trie_ngram\n",
        "# trie_prev_ngram = train_ngram_lm.trie_prev_ngram"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rj0aRgI6VBPg",
        "colab_type": "code",
        "colab": {},
        "outputId": "949f7387-be32-4478-ee1e-7575c51c85cb"
      },
      "source": [
        "trie_ngram['./<eos>/<eos>']"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "96175"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MrCV-H06VBPk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "id2token = train_ngram_lm.id2token\n",
        "token2id = train_ngram_lm.token2id"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aVioTrxLVBPo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "id2token_ngram = train_ngram_lm.id2token_ngram\n",
        "token2id_ngram = train_ngram_lm.token2id_ngram"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7kkI6aw1VBPr",
        "colab_type": "code",
        "colab": {},
        "outputId": "41f238ef-ac44-414c-9e24-83f03999f54d"
      },
      "source": [
        "random_token_id = random.randint(0, len(id2token_ngram) - 1)\n",
        "random_token = id2token_ngram[random_token_id]\n",
        "\n",
        "print (\"Token id {} ; token {}\".format(random_token_id, id2token_ngram[random_token_id]))\n",
        "print (\"Token {}; token id {}\".format(random_token, token2id_ngram[random_token]))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Token id 567850 ; token ('this', 'shirt', 'by')\n",
            "Token ('this', 'shirt', 'by'); token id 567850\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pqAfRpPXVBPv",
        "colab_type": "text"
      },
      "source": [
        "### Ngram Count & Probability"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_2Qrtpn2VBPv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# TODO: print the words for which the pd is nonzero !!! -- more intuitive than a list of numbers"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gBRnU1ucVBP1",
        "colab_type": "code",
        "colab": {},
        "outputId": "a1fcf992-80ff-4221-eeda-115b171ec113"
      },
      "source": [
        "vocab_ngram[:10], count_ngram[:10]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((('.', '<eos>', '<eos>'),\n",
              "  ('<sos>', '<sos>', 'i'),\n",
              "  ('<sos>', '<sos>', 'the'),\n",
              "  ('!', '<eos>', '<eos>'),\n",
              "  ('<sos>', '<sos>', 'they'),\n",
              "  ('<sos>', '<sos>', 'it'),\n",
              "  ('.', '.', '.'),\n",
              "  ('<sos>', '<sos>', 'this'),\n",
              "  ('<sos>', '<sos>', 'these'),\n",
              "  ('.', '.', '<eos>')),\n",
              " (96175, 26986, 9197, 8152, 6376, 5373, 4693, 4189, 3941, 3876))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "44nOuVFKVBP6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GSMjz-vNVBP9",
        "colab_type": "code",
        "colab": {},
        "outputId": "b006c116-5165-445f-ee61-37c6d7908516"
      },
      "source": [
        "c = train_ngram_lm.get_ngram_count(('an', 'older', 'coat'))\n",
        "p = train_ngram_lm.get_ngram_prob(('an', 'older', 'coat'))\n",
        "\n",
        "p1 = train_ngram_lm.get_ngram_prob(('an', 'older', 'pc'))\n",
        "p2 = train_ngram_lm.get_ngram_prob(('an', 'older', 'lady'))\n",
        "p3 = train_ngram_lm.get_ngram_prob(('an', 'older', 'watch'))\n",
        "\n",
        "pd = train_ngram_lm.get_prob_distr_ngram(('an', 'older'))\n",
        "\n",
        "c, p, p1, p2, p3, sum(pd)#, pd"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1, 0.04, 0.04, 0.04, 0.0, 1.0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4mtIdKdCVBQC",
        "colab_type": "code",
        "colab": {},
        "outputId": "142b2510-bd83-4230-92e4-37cd9f4188dc"
      },
      "source": [
        "c = train_ngram_lm.get_ngram_count(('really', 'great', 'price'))\n",
        "p = train_ngram_lm.get_ngram_prob(('really', 'great', 'price'))\n",
        "pd = train_ngram_lm.get_prob_distr_ngram(('really', 'great'))\n",
        "\n",
        "c, p, sum(pd)#, pd "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3, 0.06521739130434782, 1.0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f55rKcaFVBQG",
        "colab_type": "code",
        "colab": {},
        "outputId": "538039b7-f3f1-4dee-d726-cc9dad7e85b3"
      },
      "source": [
        "c = train_ngram_lm.get_ngram_count(('really', 'great'))\n",
        "\n",
        "c"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6vCaH0i7VBQK",
        "colab_type": "code",
        "colab": {},
        "outputId": "f53ce4c9-a3c0-4524-8ca3-b6152072f80b"
      },
      "source": [
        "c = train_ngram_lm.get_ngram_count(('.', '<eos>', '<eos>'))\n",
        "p = train_ngram_lm.get_ngram_prob(('.', '<eos>', '<eos>'))\n",
        "pd = train_ngram_lm.get_prob_distr_ngram(('.', '<eos>'))\n",
        "\n",
        "c, p, sum(pd)#, pd"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(96175, 1.0, 1.0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vJW0VdvXVBQQ",
        "colab_type": "code",
        "colab": {},
        "outputId": "4df52139-ca9c-4f11-c8f3-6a97b2953543"
      },
      "source": [
        "c = train_ngram_lm.get_ngram_count(('.', '<sos>', '<sos>'))\n",
        "\n",
        "c"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kRHJg_-pVBQX",
        "colab_type": "code",
        "colab": {},
        "outputId": "0a76f94b-24d9-4219-a1ab-3dfb75f7bddc"
      },
      "source": [
        "c = train_ngram_lm.get_ngram_count(('i', 'like', 'pandas'))\n",
        "p = train_ngram_lm.get_ngram_count(('i', 'like', 'pandas'))\n",
        "pd = train_ngram_lm.get_prob_distr_ngram(('i', 'like'))\n",
        "\n",
        "c, p, sum(pd)#, pd"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0, 0, 0.9999999999999897)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Up6wkO-4VBQa",
        "colab_type": "code",
        "colab": {},
        "outputId": "955dfb53-b783-4dd9-df4c-5d461de4093e"
      },
      "source": [
        "c = train_ngram_lm.get_ngram_count(('is', 'a', 'great'))\n",
        "p = train_ngram_lm.get_ngram_prob(('is', 'a', 'great'))\n",
        "pd = train_ngram_lm.get_prob_distr_ngram(('is', 'a'))\n",
        "\n",
        "c, p, sum(pd)#, pd"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(266, 0.09761467889908257, 1.0000000000000142)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gh7edrcsVBQe",
        "colab_type": "code",
        "colab": {},
        "outputId": "ec7edf0a-692d-4424-bc27-326638b6612f"
      },
      "source": [
        "c = train_ngram_lm.get_ngram_count(('send', 'it', 'back'))\n",
        "p = train_ngram_lm.get_ngram_prob(('send', 'it', 'back'))\n",
        "pd = train_ngram_lm.get_prob_distr_ngram(('send', 'it', 'back'))\n",
        "\n",
        "c, p, sum(pd)#, pd"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(28, 0.9032258064516129, 1.0000000000000657)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LuSyYgpNVBQi",
        "colab_type": "code",
        "colab": {},
        "outputId": "9ccf55c2-156e-43b8-90be-3caefa75d027"
      },
      "source": [
        "c = train_ngram_lm.get_ngram_count(('i', 'like', 'these', 'pictures'))\n",
        "p = train_ngram_lm.get_ngram_prob(('i', 'like', 'these', 'pictures'))\n",
        "pd = train_ngram_lm.get_prob_distr_ngram(('i', 'like', 'these'))\n",
        "\n",
        "c, p, sum(pd)#, pd"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0, 0, 1.0000000000000657)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AkQW2UEsVBQm",
        "colab_type": "text"
      },
      "source": [
        "## Add-One Smoothing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6KhbVJU0VBQn",
        "colab_type": "text"
      },
      "source": [
        "## $$P(w_i|w_{i−n+1}, ..., w_{i−2}, w_{i−1}) \\approx \\frac{1 + c(w_{i−n+1}, ..., w_{i−2}, w_{i−1}, w_i)}{\\mid V\\mid + \\sum_{w \\in V} c(w_{i−n+1}, ..., w_{i−2}, w_{i−1}, w)}$$\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Hp3Z6-_VBQo",
        "colab_type": "code",
        "colab": {},
        "outputId": "c27718c5-b022-4006-fc79-3f38ce0405d0"
      },
      "source": [
        "p = train_ngram_lm.get_ngram_prob_add_one_smoothing(('.', '<sos>', '<sos>'))\n",
        "p"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4.806305873305777e-05"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PH-qhM1RVBQq",
        "colab_type": "code",
        "colab": {},
        "outputId": "abf37859-3f14-4e61-ecc5-fb998cc3a087"
      },
      "source": [
        "p = train_ngram_lm.get_ngram_prob_add_one_smoothing(('i', 'like', 'pandas'))\n",
        "p"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4.504098729844158e-05"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5lmpyqGeVBQt",
        "colab_type": "code",
        "colab": {},
        "outputId": "bfed205d-4ae6-404a-a38d-26dec2892f31"
      },
      "source": [
        "p = train_ngram_lm.get_ngram_prob_add_one_smoothing(('i', 'like', 'this'))\n",
        "p"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.004323934780650392"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lCQIJ2bIVBQv",
        "colab_type": "code",
        "colab": {},
        "outputId": "d0239011-e341-4bc4-8bf9-1d19daef58dd"
      },
      "source": [
        "p = train_ngram_lm.get_ngram_prob_add_one_smoothing(('really', 'great', 'price'))\n",
        "p"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.0001918281220026856"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 81
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pmdyn2FTVBQy",
        "colab_type": "code",
        "colab": {},
        "outputId": "7b437af1-92d6-436e-d64f-e67277623190"
      },
      "source": [
        "p = train_ngram_lm.get_ngram_prob_add_one_smoothing(('send', 'it', 'back'))\n",
        "p"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.0013917550511110045"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 82
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6kMCrs4wVBQ1",
        "colab_type": "code",
        "colab": {},
        "outputId": "fab05c94-08ad-4869-bd3e-7c7924a486f2"
      },
      "source": [
        "p = train_ngram_lm.get_ngram_prob_add_one_smoothing(('.', '<eos>', '<eos>'))\n",
        "p"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8221506056539096"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 83
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1l9umbt2VBQ4",
        "colab_type": "text"
      },
      "source": [
        "## Additive Smoothing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vQGdAjKpVBQ4",
        "colab_type": "text"
      },
      "source": [
        "## $$P(w_i|w_{i−n+1}, ..., w_{i−2}, w_{i−1}) \\approx \\frac{\\delta + c(w_{i−n+1}, ..., w_{i−2}, w_{i−1}, w_i)}{\\delta\\mid V\\mid + \\sum_{w \\in V} c(w_{i−n+1}, ..., w_{i−2}, w_{i−1}, w)}$$\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l-1OuD_QVBQ5",
        "colab_type": "code",
        "colab": {},
        "outputId": "77937a5b-f32e-4fd2-f52c-54eb0d859397"
      },
      "source": [
        "p = train_ngram_lm.get_ngram_prob_additive_smoothing(('.', '<sos>', '<sos>'), delta = 0.5)\n",
        "p"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4.806305873305777e-05"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 84
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "so8Qzm8bVBQ_",
        "colab_type": "code",
        "colab": {},
        "outputId": "fa7c8d8d-4bb3-40f6-8878-1ac974319adc"
      },
      "source": [
        "p = train_ngram_lm.get_ngram_prob_additive_smoothing(('i', 'like', 'pandas'), delta = 0.5)\n",
        "p"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4.237647258242224e-05"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 85
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k6KzN6epVBRE",
        "colab_type": "code",
        "colab": {},
        "outputId": "41f7d534-23a7-4156-e9f7-b256fdc294b5"
      },
      "source": [
        "p = train_ngram_lm.get_ngram_prob_additive_smoothing(('i', 'like', 'this'), delta = 0.5)\n",
        "p"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.008093906263242648"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 86
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "35C5AOXhVBRI",
        "colab_type": "code",
        "colab": {},
        "outputId": "833b85d2-e1cb-41ce-8c5e-95221c4ab460"
      },
      "source": [
        "p = train_ngram_lm.get_ngram_prob_additive_smoothing(('really', 'great', 'price'), delta = 0.5)\n",
        "p"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.00033496028328069673"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 87
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IZ2SS9zQVBRL",
        "colab_type": "code",
        "colab": {},
        "outputId": "647d9a1c-418a-4457-c988-628967f899cc"
      },
      "source": [
        "p = train_ngram_lm.get_ngram_prob_additive_smoothing(('send', 'it', 'back'), delta = 0.5)\n",
        "p"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.0027314548591144336"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 88
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YIUY53YmVBRO",
        "colab_type": "code",
        "colab": {},
        "outputId": "43b3d1a6-98ea-45ce-f917-4fa81afa9fc8"
      },
      "source": [
        "p = train_ngram_lm.get_ngram_prob_additive_smoothing(('.', '<eos>', '<eos>'), delta = 0.5)\n",
        "p"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9023954287001069"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 89
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Io7gSo_UVBRR",
        "colab_type": "text"
      },
      "source": [
        "### Changing the Parameter $\\delta$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bHHQD7NOVBRS",
        "colab_type": "code",
        "colab": {},
        "outputId": "bf568e20-e57a-4c5e-f2a8-931384d82a5c"
      },
      "source": [
        "# small delta --> closer to no smoothing  (1.0)\n",
        "p = train_ngram_lm.get_ngram_prob_additive_smoothing(('.', '<eos>', '<eos>'), delta = 0.1)\n",
        "p"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9788256343658784"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 90
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pvdDWkDuVBRV",
        "colab_type": "code",
        "colab": {},
        "outputId": "7dcd2908-bbd5-4c05-dd21-86bec17e98ad"
      },
      "source": [
        "# arge delta --> closer to add-one smoothing (0.58)\n",
        "p = train_ngram_lm.get_ngram_prob_additive_smoothing(('.', '<eos>', '<eos>'), delta = 0.9)\n",
        "p"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8370371208455323"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 91
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "09Nd_q8VVBRZ",
        "colab_type": "text"
      },
      "source": [
        "## Linear Interpolation Smoothing (Jelinek-Mercer)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M48QdNS1VBRa",
        "colab_type": "text"
      },
      "source": [
        "### $$P(w_i|w_{i−n+1}, ..., w_{i−2}, w_{i−1}) \\approx \\alpha_n P(w_i|w_{i−n+1}, ..., w_{i−2}, w_{i−1}) + (1 - \\alpha_n) P(w|w_{i−n+2}, ..., w_{i−2}, w_{i−1})$$\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o5LSDE3AVBRb",
        "colab_type": "code",
        "colab": {},
        "outputId": "af772e39-9bd9-49c1-e63f-8450f73aa76d"
      },
      "source": [
        "p = train_ngram_lm.get_ngram_prob_interpolation_smoothing(('.', '<sos>', '<sos>'), alpha = 0.8)\n",
        "p"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 92
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GIEiI3ddVBRd",
        "colab_type": "code",
        "colab": {},
        "outputId": "2dd2a502-f227-47df-e95a-1692ddb24a3d"
      },
      "source": [
        "p = train_ngram_lm.get_ngram_prob_interpolation_smoothing(('i', 'like', 'pandas'), alpha = 0.8)\n",
        "p"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 93
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fSWAD4IyVBRg",
        "colab_type": "code",
        "colab": {},
        "outputId": "fc6e97b4-6780-4ebd-d42d-df61d6148fff"
      },
      "source": [
        "p = train_ngram_lm.get_ngram_prob_interpolation_smoothing(('i', 'like', 'this'), alpha = 0.8)\n",
        "p"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.054441260744985676"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 94
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kKmth042VBRk",
        "colab_type": "code",
        "colab": {},
        "outputId": "31326eec-9412-4ea0-ef2f-54c1673b648f"
      },
      "source": [
        "p = train_ngram_lm.get_ngram_prob_interpolation_smoothing(('really', 'great', 'price'), alpha = 0.8)\n",
        "p"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.052173913043478265"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 95
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ch_lVgvhVBRn",
        "colab_type": "code",
        "colab": {},
        "outputId": "77a02864-590d-4ac0-eda0-a8f962e919cf"
      },
      "source": [
        "p = train_ngram_lm.get_ngram_prob_interpolation_smoothing(('send', 'it', 'back'), alpha = 0.8)\n",
        "p"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7225806451612904"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 96
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yxCu_XoQVBRp",
        "colab_type": "text"
      },
      "source": [
        "### Changing the Parameter $\\alpha$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RHPgr71dVBRq",
        "colab_type": "code",
        "colab": {},
        "outputId": "8c48b4e2-06b4-4c22-e6db-4c9fd8ffe2c1"
      },
      "source": [
        "# small delta --> closer to no smoothing  (1.0)\n",
        "p = train_ngram_lm.get_ngram_prob_interpolation_smoothing(('.', '<eos>', '<eos>'), alpha = 0.8)\n",
        "p"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 97
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KYmntAXrVBRt",
        "colab_type": "code",
        "colab": {},
        "outputId": "5121861d-d5a6-4d2d-faf3-2fb587542b6d"
      },
      "source": [
        "# small delta --> closer to no smoothing  (1.0)\n",
        "p = train_ngram_lm.get_ngram_prob_interpolation_smoothing(('.', '<eos>', '<eos>'), alpha = 0.5)\n",
        "p"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.5"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 98
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VGHgral7VBRv",
        "colab_type": "code",
        "colab": {},
        "outputId": "d3457c28-0069-4d15-9cb8-c1bf42315005"
      },
      "source": [
        "# small delta --> closer to no smoothing  (1.0)\n",
        "p = train_ngram_lm.get_ngram_prob_interpolation_smoothing(('.', '<eos>', '<eos>'), alpha = 0.2)\n",
        "p"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.2"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 99
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ehVxxzEPVBRy",
        "colab_type": "text"
      },
      "source": [
        "## Linear Interpolation with Absolute Discounting"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tOoXCjQ9VBRz",
        "colab_type": "text"
      },
      "source": [
        "### $$p_{bi}(w|v) = max ({ \\frac{N(v, w) - b_{bi}}{N(v)}, 0)  + b_{bi} \\frac{V - N_0(v, \\cdot)}{N(v)} p_{uni}(w) \\large}$$\n",
        "\n",
        "### $$p_{uni}(w) = max ({ \\frac{N(w) - b_{uni}}{N}, 0)  + b_{uni} \\frac{V - N_0(\\cdot)}{N} \\frac{1}{V}}$$\n",
        "\n",
        "### $$b_{bi} = \\frac{N_1(\\cdot, \\cdot)}{N_1(\\cdot, \\cdot) + 2*N_2(\\cdot, \\cdot)}$$\n",
        "\n",
        "### $$b_{uni} = \\frac{N_1(\\cdot)}{N_1(\\cdot) + 2*N_2(\\cdot)}$$\n",
        "\n",
        "\n",
        "### $$N_r(\\cdot) = \\sum_{w: N(w) = r} 1$$\n",
        "\n",
        "### $$N_r(\\cdot, \\cdot) = \\sum_{v, w: N(v, w) = r} 1$$\n",
        "\n",
        "### $$N_r(v, \\cdot) = \\sum_{w: N(v, w) = r} 1$$\n",
        "\n",
        "### V is the number of words in the vocabulary\n",
        "\n",
        "### $N_r(\\cdot, \\cdot)$ and $N_r(\\cdot)$  are the count-counts for bigrams and unigrams respectively $\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VIM7ckMUVBR0",
        "colab_type": "text"
      },
      "source": [
        "### Remember to check that probabilities sum up to one:\n",
        "### $$\\sum_w p_{bi}(w|v) = \\sum_w p_{uni}(w) = 1$$\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4JU9Gg3VVBR1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# y = \"m\"\n",
        "# x = \"'\"\n",
        "\n",
        "# z = train_ngram_lm.get_p_bi(y, x)\n",
        "# z"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r_5G5e50VBR3",
        "colab_type": "code",
        "colab": {},
        "outputId": "477bc423-45b5-4652-89ca-8b7da15865a0"
      },
      "source": [
        "train_ngram[:3]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[('<sos>', '<sos>', 'this'),\n",
              "  ('<sos>', 'this', 'is'),\n",
              "  ('this', 'is', 'a'),\n",
              "  ('is', 'a', 'great'),\n",
              "  ('a', 'great', 'tutu'),\n",
              "  ('great', 'tutu', 'and'),\n",
              "  ('tutu', 'and', 'at'),\n",
              "  ('and', 'at', 'a'),\n",
              "  ('at', 'a', 'really'),\n",
              "  ('a', 'really', 'great'),\n",
              "  ('really', 'great', 'price'),\n",
              "  ('great', 'price', '.'),\n",
              "  ('price', '.', '<eos>'),\n",
              "  ('.', '<eos>', '<eos>')],\n",
              " [('<sos>', '<sos>', 'it'),\n",
              "  ('<sos>', 'it', 'doesn'),\n",
              "  ('it', 'doesn', \"'\"),\n",
              "  ('doesn', \"'\", 't'),\n",
              "  (\"'\", 't', 'look'),\n",
              "  ('t', 'look', 'cheap'),\n",
              "  ('look', 'cheap', 'at'),\n",
              "  ('cheap', 'at', 'all'),\n",
              "  ('at', 'all', '.'),\n",
              "  ('all', '.', '<eos>'),\n",
              "  ('.', '<eos>', '<eos>')],\n",
              " [('<sos>', '<sos>', 'i'),\n",
              "  ('<sos>', 'i', \"'\"),\n",
              "  ('i', \"'\", 'm'),\n",
              "  (\"'\", 'm', 'so'),\n",
              "  ('m', 'so', 'glad'),\n",
              "  ('so', 'glad', 'i'),\n",
              "  ('glad', 'i', 'looked'),\n",
              "  ('i', 'looked', 'on'),\n",
              "  ('looked', 'on', 'amazon'),\n",
              "  ('on', 'amazon', 'and'),\n",
              "  ('amazon', 'and', 'found'),\n",
              "  ('and', 'found', 'such'),\n",
              "  ('found', 'such', 'an'),\n",
              "  ('such', 'an', 'affordable'),\n",
              "  ('an', 'affordable', 'tutu'),\n",
              "  ('affordable', 'tutu', 'that'),\n",
              "  ('tutu', 'that', 'isn'),\n",
              "  ('that', 'isn', \"'\"),\n",
              "  ('isn', \"'\", 't'),\n",
              "  (\"'\", 't', 'made'),\n",
              "  ('t', 'made', 'poorly'),\n",
              "  ('made', 'poorly', '.'),\n",
              "  ('poorly', '.', '<eos>'),\n",
              "  ('.', '<eos>', '<eos>')]]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 101
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L-ArJJvdVBR8",
        "colab_type": "text"
      },
      "source": [
        "## Kneser-Ney Smoothing (best to use in practice!) http://smithamilli.com/blog/kneser-ney/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zXYDvh35VBR9",
        "colab_type": "text"
      },
      "source": [
        "### Bigram LM\n",
        "###  $$p(s) = \\prod_{i = 1} ^ {N + 1} p(w_i | w_{i-1})$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YUt7s8h3VBR-",
        "colab_type": "text"
      },
      "source": [
        "## Likelihood of a Sentence"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7ci00G6wVBR-",
        "colab_type": "text"
      },
      "source": [
        "### Bigram LM: $$ p(i \\; love \\; this \\; light) = p(i|\\cdot) \\; p(love|i)\\;  p(this|love)\\;  p(light|this) \\\\\n",
        "\\approx \\frac{c(i, \\cdot)}{\\sum_w c(\\cdot, \\; w)} \\; \\frac{c(love, i)}{\\sum_wc(i, \\; w)}\\;  \\frac{c(this, love)}{\\sum_wc(love, \\;w)}\\;  \\frac{c(light, this)}{\\sum_wc(this, \\;w)}$$ \n",
        "\n",
        "### Trigram LM: $$ p(i \\; love \\; this  \\;light) = p(i|\\cdot, \\cdot) \\; p(love|\\cdot, i) \\; p(this|i, love)\\;  p(light|love, this)$$ \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-lyaQpyVVBR_",
        "colab_type": "text"
      },
      "source": [
        "### Score Sentences"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9kt0APn8VBSA",
        "colab_type": "code",
        "colab": {},
        "outputId": "fab892bc-86c8-472a-e22a-f74d8de587dc"
      },
      "source": [
        "n = 3\n",
        "sentence = [['this', 'is', 'a', 'great', 'tutu']]\n",
        "print(sentence)\n",
        "ps = train_ngram_lm.get_prob_sentence(sentence)\n",
        "ss =  train_ngram_lm.get_score_sentence(sentence)\n",
        "ps, ss"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[['this', 'is', 'a', 'great', 'tutu']]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.0, 5.127565397867753e+77)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 102
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "plI2FrtSVBSC",
        "colab_type": "code",
        "colab": {},
        "outputId": "2c1e474e-2d40-4a10-d923-b96870eae2d8"
      },
      "source": [
        "n = 3\n",
        "sentence = [['this', 'is', 'a', 'great', 'tutu', 'and', 'at', 'a', 'really', 'great', 'price', '.']]\n",
        "print(sentence)\n",
        "ps = train_ngram_lm.get_prob_sentence(sentence)\n",
        "ss = train_ngram_lm.get_score_sentence(sentence)\n",
        "ps, ss"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[['this', 'is', 'a', 'great', 'tutu', 'and', 'at', 'a', 'really', 'great', 'price', '.']]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(4.2919413175965264e-13, 6.675591427844734)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 103
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "waf8vRO9VBSG",
        "colab_type": "text"
      },
      "source": [
        "## Sentence Generation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B0yrPCEtVBSH",
        "colab_type": "text"
      },
      "source": [
        "#### No Context"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MLt7CTJ_VBSJ",
        "colab_type": "code",
        "colab": {},
        "outputId": "497477bb-1ab1-4ee2-8004-f0ae3395e6ee"
      },
      "source": [
        "num_tokens = 5\n",
        "generated_sentence = train_ngram_lm.generate_sentence(num_tokens)\n",
        "generated_sentence\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "the\n",
            "the sateen\n",
            "the sateen fabric\n",
            "the sateen fabric is\n",
            "the sateen fabric is 34\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'the sateen fabric is 34'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 104
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9J7pTbtyVBSM",
        "colab_type": "code",
        "colab": {},
        "outputId": "55569384-0007-4be3-c423-7b80ba64e5ec"
      },
      "source": [
        "num_tokens = 10\n",
        "generated_sentence = train_ngram_lm.generate_sentence(num_tokens, context=('i', 'like', 'the'))\n",
        "generated_sentence\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "picture\n",
            "picture .\n",
            "picture . <eos>\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'picture . <eos>'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 105
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bcXAHPk6VBSO",
        "colab_type": "code",
        "colab": {},
        "outputId": "6350995f-f4b7-44d0-d04b-65fd8983ee46"
      },
      "source": [
        "num_tokens = 20\n",
        "generated_sentence = train_ngram_lm.generate_sentence(num_tokens)\n",
        "generated_sentence\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "i\n",
            "i was\n",
            "i was excited\n",
            "i was excited because\n",
            "i was excited because i\n",
            "i was excited because i wear\n",
            "i was excited because i wear them\n",
            "i was excited because i wear them outside\n",
            "i was excited because i wear them outside or\n",
            "i was excited because i wear them outside or to\n",
            "i was excited because i wear them outside or to work\n",
            "i was excited because i wear them outside or to work .\n",
            "i was excited because i wear them outside or to work . <eos>\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'i was excited because i wear them outside or to work . <eos>'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 106
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O-jn5iMgVBSQ",
        "colab_type": "text"
      },
      "source": [
        "#### With Context"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DgK3JdyKVBST",
        "colab_type": "code",
        "colab": {},
        "outputId": "90927902-18cf-4eb2-da2a-2115f6e7b42c"
      },
      "source": [
        "num_tokens = 5\n",
        "generated_sentence = train_ngram_lm.generate_sentence(num_tokens, context=('i', 'like', 'the'))\n",
        "generated_sentence\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "medium\n",
            "medium with\n",
            "medium with sports\n",
            "medium with sports bras\n",
            "medium with sports bras because\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'medium with sports bras because'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 107
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QgAUnAOVVBSV",
        "colab_type": "code",
        "colab": {},
        "outputId": "6ba8f0f9-a691-4f3c-b1c0-a39ca6259533"
      },
      "source": [
        "num_tokens = 10\n",
        "generated_sentence = train_ngram_lm.generate_sentence(num_tokens, context=('i', 'like', 'the'))\n",
        "generated_sentence\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "boots\n",
            "boots are\n",
            "boots are over\n",
            "boots are over 6\n",
            "boots are over 6 years\n",
            "boots are over 6 years now\n",
            "boots are over 6 years now ,\n",
            "boots are over 6 years now , i\n",
            "boots are over 6 years now , i am\n",
            "boots are over 6 years now , i am 5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'boots are over 6 years now , i am 5'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 108
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rYQXVs-zVBSY",
        "colab_type": "code",
        "colab": {},
        "outputId": "d37e3344-4b5b-4326-daee-77da82fc01f1"
      },
      "source": [
        "num_tokens = 20\n",
        "generated_sentence = train_ngram_lm.generate_sentence(num_tokens, context=('i', 'like', 'the'))\n",
        "generated_sentence\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "band\n",
            "band was\n",
            "band was still\n",
            "band was still working\n",
            "band was still working great\n",
            "band was still working great just\n",
            "band was still working great just as\n",
            "band was still working great just as there\n",
            "band was still working great just as there is\n",
            "band was still working great just as there is nothing\n",
            "band was still working great just as there is nothing like\n",
            "band was still working great just as there is nothing like the\n",
            "band was still working great just as there is nothing like the spanx\n",
            "band was still working great just as there is nothing like the spanx run\n",
            "band was still working great just as there is nothing like the spanx run a\n",
            "band was still working great just as there is nothing like the spanx run a bit\n",
            "band was still working great just as there is nothing like the spanx run a bit after\n",
            "band was still working great just as there is nothing like the spanx run a bit after wearing\n",
            "band was still working great just as there is nothing like the spanx run a bit after wearing these\n",
            "band was still working great just as there is nothing like the spanx run a bit after wearing these .\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'band was still working great just as there is nothing like the spanx run a bit after wearing these .'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 109
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xGHmqJ-rVBSa",
        "colab_type": "code",
        "colab": {},
        "outputId": "4c88649c-1810-4a46-a551-a9228a7cc85f"
      },
      "source": [
        "num_tokens = 10\n",
        "generated_sentence = train_ngram_lm.generate_sentence(num_tokens, context=('the', 'worst'))\n",
        "generated_sentence\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "bras\n",
            "bras i\n",
            "bras i bought\n",
            "bras i bought these\n",
            "bras i bought these for\n",
            "bras i bought these for narrows\n",
            "bras i bought these for narrows after\n",
            "bras i bought these for narrows after finding\n",
            "bras i bought these for narrows after finding the\n",
            "bras i bought these for narrows after finding the size\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'bras i bought these for narrows after finding the size'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 110
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "msTO93puVBSc",
        "colab_type": "code",
        "colab": {},
        "outputId": "9ae9ee67-60b5-4986-b2e5-e6f1cbcabad3"
      },
      "source": [
        "num_tokens = 5\n",
        "generated_sentence = train_ngram_lm.generate_sentence(num_tokens, context=('the', 'best'))\n",
        "generated_sentence\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            ".\n",
            ". <eos>\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'. <eos>'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 111
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "56h3o_OPVBSf",
        "colab_type": "code",
        "colab": {},
        "outputId": "a67c6180-f4a6-45c9-b02c-d6a561a97073"
      },
      "source": [
        "num_tokens = 5\n",
        "generated_sentence = train_ngram_lm.generate_sentence(num_tokens, context=('not', 'what'))\n",
        "generated_sentence\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "arrived\n",
            "arrived at\n",
            "arrived at the\n",
            "arrived at the center\n",
            "arrived at the center .\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'arrived at the center .'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 112
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DGNuNpCsVBSk",
        "colab_type": "code",
        "colab": {},
        "outputId": "dcdf7321-d4eb-424a-edf3-1ea3da70acab"
      },
      "source": [
        "num_tokens = 5\n",
        "generated_sentence = train_ngram_lm.generate_sentence(num_tokens, context=('i', 'will'))\n",
        "generated_sentence\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "give\n",
            "give it\n",
            "give it to\n",
            "give it to a\n",
            "give it to a dangle\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'give it to a dangle'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 113
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pp0FjbwJVBSm",
        "colab_type": "text"
      },
      "source": [
        "## Log-Likelihood (n-gram)\n",
        "## $$LL = \\sum_{j=1}^{K} \\sum_{i=1}^{T_j + 1} log p_{bi}(w_{j, i} | w_{j, n - i + 1}, \\cdot, w_{j, i - 2}, w_{j, i - 1})$$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ot2OsECWVBSp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ATVjSctjVBSr",
        "colab_type": "text"
      },
      "source": [
        "## Perplexity\n",
        "## $$PP = exp(-\\frac{LL}{\\sum_j(T_j + 1)})$$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "akR6gh-IVBSr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ppl_train = train_ngram_lm.get_perplexity(train_data_tokenized, subsample=10)\n",
        "ppl_valid = train_ngram_lm.get_perplexity(valid_data_tokenized, subsample=10)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KYCI8yoaVBSt",
        "colab_type": "code",
        "colab": {},
        "outputId": "24bd7fd6-5bab-4dbf-9568-c5b6f9994f3f"
      },
      "source": [
        "ppl_valid, ppl_train"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1.054956118557522e+16, 785.4807625424293)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 115
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OW2oaaRMVBSw",
        "colab_type": "text"
      },
      "source": [
        "### Interpolation Smoothing - varying N"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HQka6jaJVBSw",
        "colab_type": "code",
        "colab": {},
        "outputId": "7c7fdcea-e9d0-496d-d5e2-3fc08c219a58"
      },
      "source": [
        "# Interpolation Smoothing, N = 2\n",
        "train_ngram_lm_interp2 = NgramLM(train_data_tokenized, all_tokens_train, n=2, smoothing='interpolation')\n",
        "valid_ngram_lm_interp2 = NgramLM(valid_data_tokenized, all_tokens_valid, n=2, smoothing='interpolation')\n",
        "\n",
        "ppl_train_no_interp2 = train_ngram_lm_interp2.get_perplexity(train_data_tokenized, subsample=10)\n",
        "ppl_valid_no_interp2 = train_ngram_lm_interp2.get_perplexity(valid_data_tokenized, subsample=10)\n",
        "\n",
        "ppl_valid_no_interp2, ppl_train_no_interp2\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3198493286877.7236, 1789.0177288795328)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 116
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "78l_1rI9VBSz",
        "colab_type": "code",
        "colab": {},
        "outputId": "0fbf2355-1ce5-4a26-8160-fb55b33f4f1b"
      },
      "source": [
        "# Interpolation Smoothing, N = 3\n",
        "train_ngram_lm_interp3 = NgramLM(train_data_tokenized, all_tokens_train, n=3, smoothing='interpolation')\n",
        "valid_ngram_lm_interp3 = NgramLM(valid_data_tokenized, all_tokens_valid, n=3, smoothing='interpolation')\n",
        "\n",
        "ppl_train_no_interp3 = train_ngram_lm_interp3.get_perplexity(train_data_tokenized, subsample=10)\n",
        "ppl_valid_no_interp3 = train_ngram_lm_interp3.get_perplexity(valid_data_tokenized, subsample=10)\n",
        "\n",
        "ppl_valid_no_interp3, ppl_train_no_interp3\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-117-26e170ef221c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Interpolation Smoothing, N = 3\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mtrain_ngram_lm_interp3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNgramLM\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data_tokenized\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mall_tokens_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msmoothing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'interpolation'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mvalid_ngram_lm_interp3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNgramLM\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalid_data_tokenized\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mall_tokens_valid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msmoothing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'interpolation'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mppl_train_no_interp3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_ngram_lm_interp3\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_perplexity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data_tokenized\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubsample\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/Dropbox/Aims/AIMS Ghana/AMMI/AMMI-NLP/Part 02/001_LM/2019/c_utils/ngram_utils.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, tokenized_data, all_tokens, n, frac_vocab, smoothing, delta, alpha)\u001b[0m\n\u001b[1;32m    113\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrie_ngram\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_trie\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrie_unigram\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_trie\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 115\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrie_bigram\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_trie\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    116\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrie_trigram\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_trie\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/Dropbox/Aims/AIMS Ghana/AMMI/AMMI-NLP/Part 02/001_LM/2019/c_utils/ngram_utils.py\u001b[0m in \u001b[0;36mmake_trie\u001b[0;34m(self, n)\u001b[0m\n\u001b[1;32m    196\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m         \u001b[0mtrie\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpygtrie\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mStringTrie\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 198\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mvn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcn\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab_ngram\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcount_ngram\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    199\u001b[0m             \u001b[0mtn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_to_trie\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtn\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrie\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0XdNlgYBVBS0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Interpolation Smoothing, N = 5\n",
        "train_ngram_lm_interp5 = NgramLM(train_data_tokenized, all_tokens_train, n=5, smoothing='interpolation')\n",
        "valid_ngram_lm_interp5 = NgramLM(valid_data_tokenized, all_tokens_valid, n=5, smoothing='interpolation')\n",
        "\n",
        "ppl_train_no_interp5 = train_ngram_lm_interp5.get_perplexity(train_data_tokenized, subsample=10)\n",
        "ppl_valid_no_interp5 = train_ngram_lm_interp5.get_perplexity(valid_data_tokenized, subsample=10)\n",
        "\n",
        "ppl_valid_no_interp5, ppl_train_no_interp5\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WdE005NKVBS3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Interpolation Smoothing, N = 7\n",
        "train_ngram_lm_interp7 = NgramLM(train_data_tokenized, all_tokens_train, n=7, smoothing='interpolation')\n",
        "valid_ngram_lm_interp7 = NgramLM(valid_data_tokenized, all_tokens_valid, n=7, smoothing='interpolation')\n",
        "\n",
        "ppl_train_no_interp7 = train_ngram_lm_interp7.get_perplexity(train_data_tokenized, subsample=10)\n",
        "ppl_valid_no_interp7 = train_ngram_lm_interp7.get_perplexity(valid_data_tokenized, subsample=10)\n",
        "\n",
        "ppl_valid_no_interp7, ppl_train_no_interp7\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QqINvmz1VBS4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Interpolation Smoothing, N = 10\n",
        "train_ngram_lm_interp10 = NgramLM(train_data_tokenized, all_tokens_train, n=10, smoothing='interpolation')\n",
        "valid_ngram_lm_interp10 = NgramLM(valid_data_tokenized, all_tokens_valid, n=10, smoothing='interpolation')\n",
        "\n",
        "ppl_train_no_interp10 = train_ngram_lm_interp10.get_perplexity(train_data_tokenized, subsample=10)\n",
        "ppl_valid_no_interp10 = train_ngram_lm_interp10.get_perplexity(valid_data_tokenized, subsample=10)\n",
        "\n",
        "ppl_valid_no_interp10, ppl_train_no_interp10\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wbpchBK9VBS6",
        "colab_type": "text"
      },
      "source": [
        "### Let's Compare Different Smoothing Techniques"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yG8ysWsyVBS-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# No Smoothing\n",
        "train_ngram_lm_no_smoothing = NgramLM(train_data_tokenized, all_tokens_train, n=7)\n",
        "valid_ngram_lm_no_smoothing = NgramLM(valid_data_tokenized, all_tokens_valid, n=7)\n",
        "\n",
        "ppl_train_no_smoothing = train_ngram_lm_no_smoothing.get_perplexity(train_data_tokenized, subsample=10)\n",
        "ppl_valid_no_smoothing = train_ngram_lm_no_smoothing.get_perplexity(valid_data_tokenized, subsample=10)\n",
        "\n",
        "ppl_valid_no_smoothing, ppl_train_no_smoothing\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gy9QOzwiVBTA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Additive Smoothing\n",
        "train_ngram_lm_additive = NgramLM(train_data_tokenized, all_tokens_train, n=7, smoothing='additive', delta=0.5)\n",
        "valid_ngram_lm_additive = NgramLM(valid_data_tokenized, all_tokens_valid, n=7, smoothing='additive', delta=0.5)\n",
        "\n",
        "ppl_train_no_additive = train_ngram_lm_additive.get_perplexity(train_data_tokenized, subsample=10)\n",
        "ppl_valid_no_additive = train_ngram_lm_additive.get_perplexity(valid_data_tokenized, subsample=10)\n",
        "\n",
        "ppl_valid_no_additive, ppl_train_no_additive\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DcAiQycZVBTB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Additive Smoothing\n",
        "train_ngram_lm_additive_d2 = NgramLM(train_data_tokenized, all_tokens_train, n=7, smoothing='additive', delta=0.2)\n",
        "valid_ngram_lm_additive_d2 = NgramLM(valid_data_tokenized, all_tokens_valid, n=7, smoothing='additive', delta=0.2)\n",
        "\n",
        "ppl_train_no_additive_d2 = train_ngram_lm_additive_d2.get_perplexity(train_data_tokenized, subsample=10)\n",
        "ppl_valid_no_additive_d2 = train_ngram_lm_additive_d2.get_perplexity(valid_data_tokenized, subsample=10)\n",
        "\n",
        "ppl_valid_no_additive_d2, ppl_train_no_additive_d2\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "147Vp3zJVBTE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Additive Smoothing\n",
        "train_ngram_lm_additive_d8 = NgramLM(train_data_tokenized, all_tokens_train, n=7, smoothing='additive', delta=0.8)\n",
        "valid_ngram_lm_additive_d8 = NgramLM(valid_data_tokenized, all_tokens_valid, n=7, smoothing='additive', delta=0.8)\n",
        "\n",
        "ppl_train_no_additive_d8 = train_ngram_lm_additive_d8.get_perplexity(train_data_tokenized, subsample=10)\n",
        "ppl_valid_no_additive_d8 = train_ngram_lm_additive_d8.get_perplexity(valid_data_tokenized, subsample=10)\n",
        "\n",
        "ppl_valid_no_additive_d8, ppl_train_no_additive_d8\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4mq-kQ3oVBTG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Additive Smoothing\n",
        "train_ngram_lm_add1 = NgramLM(train_data_tokenized, all_tokens_train, n=7, smoothing='add-one')\n",
        "valid_ngram_lm_add1 = NgramLM(valid_data_tokenized, all_tokens_valid, n=7, smoothing='add-one')\n",
        "\n",
        "ppl_train_no_add1 = train_ngram_lm_add1.get_perplexity(train_data_tokenized, subsample=10)\n",
        "ppl_valid_no_add1 = train_ngram_lm_add1.get_perplexity(valid_data_tokenized, subsample=10)\n",
        "\n",
        "ppl_valid_no_add1, ppl_train_no_add1\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "55feS5z9VBTI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Interpolation Smoothing\n",
        "train_ngram_lm_interp_a2 = NgramLM(train_data_tokenized, all_tokens_train, n=7, smoothing='interpolation', alpha=0.2)\n",
        "valid_ngram_lm_interp_a2 = NgramLM(valid_data_tokenized, all_tokens_valid, n=7, smoothing='interpolation', alpha=0.2)\n",
        "\n",
        "ppl_train_no_interp_a2 = train_ngram_lm_interp_a2.get_perplexity(train_data_tokenized, subsample=10)\n",
        "ppl_valid_no_interp_a2 = train_ngram_lm_interp_a2.get_perplexity(valid_data_tokenized, subsample=10)\n",
        "\n",
        "ppl_valid_no_interp_a2, ppl_train_no_interp_a2\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SUTQ0LTfVBTJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Interpolation Smoothing\n",
        "train_ngram_lm_interp_a8 = NgramLM(train_data_tokenized, all_tokens_train, n=7, smoothing='interpolation', alpha=0.8)\n",
        "valid_ngram_lm_interp_a8 = NgramLM(valid_data_tokenized, all_tokens_valid, n=7, smoothing='interpolation', alpha=0.8)\n",
        "\n",
        "ppl_train_no_interp_a8 = train_ngram_lm_interp_a8.get_perplexity(train_data_tokenized, subsample=10)\n",
        "ppl_valid_no_interp_a8 = train_ngram_lm_interp_a8.get_perplexity(valid_data_tokenized, subsample=10)\n",
        "\n",
        "ppl_valid_no_interp_a8, ppl_train_no_interp_a8\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PaN7GqJEVBTL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Interpolation Smoothing\n",
        "train_ngram_lm_interp_a5 = NgramLM(train_data_tokenized, all_tokens_train, n=7, smoothing='interpolation', alpha=0.5)\n",
        "valid_ngram_lm_interp_a5 = NgramLM(valid_data_tokenized, all_tokens_valid, n=7, smoothing='interpolation', alpha=0.5)\n",
        "\n",
        "ppl_train_no_interp_a5 = train_ngram_lm_interp_a5.get_perplexity(train_data_tokenized, subsample=10)\n",
        "ppl_valid_no_interp_a5 = train_ngram_lm_interp_a5.get_perplexity(valid_data_tokenized, subsample=10)\n",
        "\n",
        "ppl_valid_no_interp_a5, ppl_train_no_interp_a5\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4ELMJMJ_VBTN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# # Discounted Interpolation Smoothing\n",
        "# train_ngram_lm_discount = NgramLM(train_data_tokenized, all_tokens_train, n=3, smoothing='discounting')\n",
        "# valid_ngram_lm_discount = NgramLM(valid_data_tokenized, all_tokens_valid, n=3, smoothing='discounting')\n",
        "\n",
        "# ppl_train_no_discount = train_ngram_lm_discount.get_perplexity(train_data_tokenized)\n",
        "# ppl_valid_no_discount = train_ngram_lm_discount.get_perplexity(valid_data_tokenized)\n",
        "\n",
        "# ppl_valid_no_discount, ppl_train_no_discount\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eiKBCh_sVBTQ",
        "colab_type": "text"
      },
      "source": [
        "### Additive Smoothing - varying N"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uCfot5QCVBTR",
        "colab_type": "text"
      },
      "source": [
        "### Sentence Probabilities"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xkLxp0XAVBTR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sentence = [['this', 'is', 'a', 'great', 'tutu']]\n",
        "print(sentence)\n",
        "ps = train_ngram_lm.get_prob_sentence(sentence)\n",
        "ss = train_ngram_lm.get_score_sentence(sentence)\n",
        "ps, ss"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kpPgUIPyVBTT",
        "colab_type": "code",
        "colab": {},
        "outputId": "a7cfe67c-3cdd-4d0f-bcd4-82ff1719fb55"
      },
      "source": [
        "sentence = [['this', 'is', 'a', 'great', 'tutu', 'and', 'at', 'a', 'really', 'great', 'price', '.']]\n",
        "print(sentence)\n",
        "ps = train_ngram_lm_interp3.get_prob_sentence(sentence)\n",
        "ss = train_ngram_lm_interp3.get_score_sentence(sentence)\n",
        "ps, ss"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[['this', 'is', 'a', 'great', 'tutu', 'and', 'at', 'a', 'really', 'great', 'price', '.']]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1.887615753771853e-14, 8.221273452877178)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 100
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-IRNpUeNVBTW",
        "colab_type": "code",
        "colab": {},
        "outputId": "b230e21a-a9a7-4a78-df0e-5feb6cf011fc"
      },
      "source": [
        "sentence = [['this', 'is', 'a', 'great', 'tutu', 'and', 'at', 'a', 'really', 'great', 'price', '.']]\n",
        "print(sentence)\n",
        "ps = train_ngram_lm_interp5.get_prob_sentence(sentence)\n",
        "ss = train_ngram_lm_interp5.get_score_sentence(sentence)\n",
        "ps, ss"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[['this', 'is', 'a', 'great', 'tutu', 'and', 'at', 'a', 'really', 'great', 'price', '.']]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2.0890490981023452e-07, 2.4714065720144007)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 101
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yRbr_petVBTZ",
        "colab_type": "code",
        "colab": {},
        "outputId": "61b4657e-e632-4dc9-d4c5-9c17956e48a7"
      },
      "source": [
        "sentence = [['this', 'is', 'a', 'great', 'tutu', 'and', 'at', 'a', 'really', 'great', 'price', '.']]\n",
        "print(sentence)\n",
        "ps = train_ngram_lm_interp7.get_prob_sentence(sentence)\n",
        "ss = train_ngram_lm_interp7.get_score_sentence(sentence)\n",
        "ps, ss"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[['this', 'is', 'a', 'great', 'tutu', 'and', 'at', 'a', 'really', 'great', 'price', '.']]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1.7987031324049532e-07, 2.264655425293293)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 102
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w11DndJKVBTa",
        "colab_type": "code",
        "colab": {},
        "outputId": "2fd42b27-7d37-48e5-eb7a-c452227ea5bd"
      },
      "source": [
        "sentence = [['this', 'is', 'a', 'great', 'tutu']]\n",
        "print(sentence)\n",
        "ps = train_ngram_lm_interp10.get_prob_sentence(sentence)\n",
        "ss = train_ngram_lm_interp10.get_score_sentence(sentence)\n",
        "ps, ss"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[['this', 'is', 'a', 'great', 'tutu']]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.0, 9.063042790366942e+184)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 103
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9EmJWRlqVBTc",
        "colab_type": "code",
        "colab": {},
        "outputId": "ffab46cc-532e-4526-c32a-e154527a55a4"
      },
      "source": [
        "sentence = [['this', 'is', 'a', 'great', 'tutu', 'and', 'at', 'a', 'really', 'great', 'price', '.']]\n",
        "print(sentence)\n",
        "ps = train_ngram_lm_additive.get_prob_sentence(sentence)\n",
        "ss = train_ngram_lm_additive.get_score_sentence(sentence)\n",
        "ps, ss"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[['this', 'is', 'a', 'great', 'tutu', 'and', 'at', 'a', 'really', 'great', 'price', '.']]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(9.246774960655664e-44, 339.94787908610914)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 104
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "go0d4XuIVBTe",
        "colab_type": "code",
        "colab": {},
        "outputId": "27fca20c-7923-4e28-fd06-b3f88ad3cfc6"
      },
      "source": [
        "sentence = [['i', 'like', 'pandas']]\n",
        "print(sentence)\n",
        "ps = train_ngram_lm_additive.get_prob_sentence(sentence)\n",
        "ss = train_ngram_lm_additive.get_score_sentence(sentence)\n",
        "ps, ss"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[['i', 'like', 'pandas']]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'train_ngram_lm_additive' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-257ff62052a2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0msentence\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'i'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'like'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'pandas'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_ngram_lm_additive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_prob_sentence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_ngram_lm_additive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_score_sentence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'train_ngram_lm_additive' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uiJRyV6UVBTi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sentence = [['i really like this watch']]\n",
        "print(sentence)\n",
        "ps = train_ngram_lm_additive.get_prob_sentence(sentence)\n",
        "ss = train_ngram_lm_additive.get_score_sentence(sentence)\n",
        "ps, ss"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Jthr0RKVBTl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sentence = [['my wife really likes the color of this dress']]\n",
        "print(sentence)\n",
        "ps = train_ngram_lm_additive.get_prob_sentence(sentence)\n",
        "ss = train_ngram_lm_additive.get_score_sentence(sentence)\n",
        "ps, ss"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hskUmNlOVBTo",
        "colab_type": "text"
      },
      "source": [
        "### Sentence Generation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NsXg1repVBTo",
        "colab_type": "code",
        "colab": {},
        "outputId": "3f601f95-769d-4236-ddc0-8f100c062878"
      },
      "source": [
        "num_tokens = 10\n",
        "generated_sentence = train_ngram_lm_interp3.generate_sentence(num_tokens)\n",
        "generated_sentence\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "big\n",
            "big student\n",
            "big student backpack\n",
            "big student backpack and\n",
            "big student backpack and eats\n",
            "big student backpack and eats one\n",
            "big student backpack and eats one of\n",
            "big student backpack and eats one of the\n",
            "big student backpack and eats one of the material\n",
            "big student backpack and eats one of the material didn\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'big student backpack and eats one of the material didn'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 108
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K8WA9CFGVBTs",
        "colab_type": "code",
        "colab": {},
        "outputId": "6b80dc98-f043-4a1d-fda6-b5d9f8080b8f"
      },
      "source": [
        "num_tokens = 10\n",
        "generated_sentence = train_ngram_lm_interp5.generate_sentence(num_tokens)\n",
        "generated_sentence"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "inside\n",
            "inside ,\n",
            "inside , i\n",
            "inside , i use\n",
            "inside , i use the\n",
            "inside , i use the amazon\n",
            "inside , i use the amazon visa\n",
            "inside , i use the amazon visa card\n",
            "inside , i use the amazon visa card and\n",
            "inside , i use the amazon visa card and there\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'inside , i use the amazon visa card and there'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 107
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jNtvG1xeVBTt",
        "colab_type": "code",
        "colab": {},
        "outputId": "6b1ae9c4-50e4-4da7-9887-fe50952951c6"
      },
      "source": [
        "num_tokens = 10\n",
        "generated_sentence = train_ngram_lm_interp7.generate_sentence(num_tokens)\n",
        "generated_sentence\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "they\n",
            "they are\n",
            "they are blindingly\n",
            "they are blindingly white\n",
            "they are blindingly white makes\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'they are blindingly white makes'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 111
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YnKKnHa4VBTv",
        "colab_type": "code",
        "colab": {},
        "outputId": "c2bbaf94-2e9c-47b4-9670-06f1c994f124"
      },
      "source": [
        "num_tokens = 10\n",
        "generated_sentence = train_ngram_lm_interp10.generate_sentence(num_tokens)\n",
        "generated_sentence\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "this\n",
            "this ring\n",
            "this ring was\n",
            "this ring was on\n",
            "this ring was on my\n",
            "this ring was on my wife\n",
            "this ring was on my wife '\n",
            "this ring was on my wife ' s\n",
            "this ring was on my wife ' s wish\n",
            "this ring was on my wife ' s wish list\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"this ring was on my wife ' s wish list\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 110
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6N6oxineVBTw",
        "colab_type": "code",
        "colab": {},
        "outputId": "986c47b9-218f-407c-e7a9-36d9084d2656"
      },
      "source": [
        "num_tokens = 20\n",
        "generated_sentence = train_ngram_lm_interp10.generate_sentence(num_tokens)\n",
        "generated_sentence\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "the\n",
            "the best\n",
            "the best foot\n",
            "the best foot support\n",
            "the best foot support system\n",
            "the best foot support system ,\n",
            "the best foot support system , and\n",
            "the best foot support system , and no\n",
            "the best foot support system , and no tight\n",
            "the best foot support system , and no tight toe\n",
            "the best foot support system , and no tight toe bed\n",
            "the best foot support system , and no tight toe bed .\n",
            "the best foot support system , and no tight toe bed . <eos>\n",
            "the best foot support system , and no tight toe bed . <eos> <eos>\n",
            "the best foot support system , and no tight toe bed . <eos> <eos> <eos>\n",
            "the best foot support system , and no tight toe bed . <eos> <eos> <eos> <eos>\n",
            "the best foot support system , and no tight toe bed . <eos> <eos> <eos> <eos> <eos>\n",
            "the best foot support system , and no tight toe bed . <eos> <eos> <eos> <eos> <eos> <eos>\n",
            "the best foot support system , and no tight toe bed . <eos> <eos> <eos> <eos> <eos> <eos> <eos>\n",
            "the best foot support system , and no tight toe bed . <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos>\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'the best foot support system , and no tight toe bed . <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos>'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 112
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QoH8oxDfVBTy",
        "colab_type": "code",
        "colab": {},
        "outputId": "9a3a71f1-2add-4118-a245-7017b70e0c80"
      },
      "source": [
        "num_tokens = 10\n",
        "generated_sentence = train_ngram_lm_additive.generate_sentence(num_tokens)\n",
        "generated_sentence\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "or\n",
            "or at\n",
            "or at least\n",
            "or at least nobody\n",
            "or at least nobody '\n",
            "or at least nobody ' s\n",
            "or at least nobody ' s said\n",
            "or at least nobody ' s said anything\n",
            "or at least nobody ' s said anything yet\n",
            "or at least nobody ' s said anything yet .\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"or at least nobody ' s said anything yet .\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 109
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iX6X3HaVVBT0",
        "colab_type": "code",
        "colab": {},
        "outputId": "4f7deb57-f760-4dbe-ebb1-f2a0935ac4a9"
      },
      "source": [
        "num_tokens = 10\n",
        "generated_sentence = train_ngram_lm_no_smoothing.generate_sentence(num_tokens)\n",
        "generated_sentence\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "i\n",
            "i will\n",
            "i will recommend\n",
            "i will recommend this\n",
            "i will recommend this to\n",
            "i will recommend this to my\n",
            "i will recommend this to my friends\n",
            "i will recommend this to my friends !\n",
            "i will recommend this to my friends ! <eos>\n",
            "i will recommend this to my friends ! <eos> <eos>\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'i will recommend this to my friends ! <eos> <eos>'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 113
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tqtXtFrvVBT2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W0SPnAbkVBT3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}